{
  "chat_template_file": "./chat_template/Llama3.json",
  "job_type": "fine_tune",
  "project": "emotion-chat-bot-ncu",
  "group": "Emotion Model",
  "notes": "fine tune model",
  "config": {
    "dataset": "daily_dialog_for_RG:latest",
    "base_model": "meta-llama/Meta-Llama-3-8B",
    "tokenizer": "meta-llama/Meta-Llama-3-8B",
    "num_epochs": 1,
    "system_prompt": ""
  },
  "output_dir": "./checkpoints",
  "overwrite_output_dir": true,
  "per_device_train_batch_size": 4,
  "gradient_accumulation_steps": 1,
  "learning_rate": 2e-4,
  "weight_decay": 0.001,
  "max_grad_norm": 0.3,
  "num_train_epochs": 1,
  "lr_scheduler_type": "constant",
  "warmup_ratio": 0.03,
  "max_steps": -1,
  "logging_steps": 25,
  "save_steps": 25,
  "save_total_limit": 5,
  "bf16": true,
  "fp16": false,
  "dataloader_num_workers": 16,
  "optim": "paged_adamw_32bit",
  "group_by_length": true,
  "report_to": ["wandb"],
  "gradient_checkpointing": true,
  "gradient_checkpointing_kwargs": {
    "use_reentrant": true
  },
  "auto_find_batch_size": true,
  "torch_compile": false
}
