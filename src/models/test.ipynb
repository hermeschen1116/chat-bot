{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b99f046113bfa66b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:18.276391Z",
     "start_time": "2024-09-18T16:49:18.274793Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from numpy.ma.core import shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7133720c82d0491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:32.076901Z",
     "start_time": "2024-09-18T16:49:18.279305Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "\t\"hermeschen1116/emotion_transition_from_dialog\",\n",
    "\tnum_proc=16,\n",
    "\tkeep_in_memory=True,\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ee0bd3e7e31a93d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:32.095355Z",
     "start_time": "2024-09-18T16:49:32.093153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(dataset[\"train\"][0][\"user_emotion_compositions\"][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f677f6054db29250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:32.198058Z",
     "start_time": "2024-09-18T16:49:32.196316Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a3dfab9b8bdc44f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:32.247775Z",
     "start_time": "2024-09-18T16:49:32.245675Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.models.libs import EmotionModel\n",
    "\n",
    "model = EmotionModel(attention=\"dot_product\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4a397aa5da8b079f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:32.615732Z",
     "start_time": "2024-09-18T16:49:32.293073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0355203b526245f0b509e13c6b8a8cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/958 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.models.libs import representation_evolute\n",
    "\n",
    "eval_dataset = dataset[\"test\"].map(\n",
    "\tlambda samples: {\n",
    "\t\t\"bot_emotion_representations\": [\n",
    "\t\t\trepresentation_evolute(\n",
    "\t\t\t\tmodel,\n",
    "\t\t\t\t[torch.tensor(sample[0][0]).to(device)],\n",
    "\t\t\t\t[torch.tensor(emotion).to(device) for emotion in sample[1]],\n",
    "\t\t\t)[1:]\n",
    "\t\t\tfor sample in zip(\n",
    "\t\t\t\tsamples[\"bot_initial_emotion_representation\"],\n",
    "\t\t\t\tsamples[\"user_emotion_compositions\"],\n",
    "\t\t\t)\n",
    "\t\t]\n",
    "\t},\n",
    "\tbatched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2d89526fa8d61c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:32.718539Z",
     "start_time": "2024-09-18T16:49:32.715413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1458,  0.5676,  0.2000,  0.2053,  0.6992,  0.5418,  0.3416],\n",
       "        [ 1.3333,  0.2167,  0.3927,  0.1353,  0.6972,  0.5887,  0.0757],\n",
       "        [ 1.5209, -0.1343,  0.5853,  0.0652,  0.6952,  0.6357, -0.1903],\n",
       "        [ 1.7081, -0.4853,  0.7777, -0.0049,  0.6932,  0.6827, -0.4563],\n",
       "        [ 1.8953, -0.8363,  0.9701, -0.0750,  0.6915,  0.7296, -0.7223]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(eval_dataset[0][\"bot_emotion_representations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ed0223a720ce6bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:32.776298Z",
     "start_time": "2024-09-18T16:49:32.773708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(eval_dataset[0][\"bot_emotion_representations\"]).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "12f5d7347ed91747",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:33.335749Z",
     "start_time": "2024-09-18T16:49:32.822672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8652f71ca43a497a970f22ca84535c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/958 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset = eval_dataset.map(\n",
    "\tlambda samples: {\"bot_possible_emotion\": [torch.tensor(sample).argmax(1) for sample in samples]},\n",
    "\tinput_columns=\"bot_emotion_representations\",\n",
    "\tbatched=True,\n",
    "\tnum_proc=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c0af63ee4dbf031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:33.360974Z",
     "start_time": "2024-09-18T16:49:33.355706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3040])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "eval_predictions: Tensor = torch.cat([torch.tensor(turn) for turn in eval_dataset[\"bot_possible_emotion\"]])\n",
    "eval_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2e4883649393729a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:33.408699Z",
     "start_time": "2024-09-18T16:49:33.402749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3040])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_truths: Tensor = torch.cat([torch.tensor(turn) for turn in eval_dataset[\"bot_emotion\"]])\n",
    "eval_truths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6b89fe7e7cab44fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:33.456895Z",
     "start_time": "2024-09-18T16:49:33.454775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_predictions) == len(eval_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8fa5f85796b71c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T16:49:33.514655Z",
     "start_time": "2024-09-18T16:49:33.513511Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
