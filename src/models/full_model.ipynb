{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3ca6205fd0c59f",
   "metadata": {},
   "source": "# Emotion Chat Bot"
  },
  {
   "cell_type": "code",
   "id": "1a2aa4f1318f3251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:41.845464Z",
     "start_time": "2024-09-17T16:30:39.189806Z"
    }
   },
   "source": [
    "import os.path\n",
    "import uuid\n",
    "\n",
    "import torch\n",
    "from libs import (\n",
    "\tEmotionModel,\n",
    "\tEmotionPresentationSimilarityAnalyser,\n",
    "\tResponseGeneratorPipeline,\n",
    "\tgenerate_dummy_representation,\n",
    "\tget_sentiment_composition,\n",
    ")\n",
    "from libs.FullModel import create_candidates_buffer, get_top_emotion, write_log_file\n",
    "from sympy.core.random import randint\n",
    "from torch import Tensor\n",
    "from transformers import (\n",
    "\tAutoModelForSequenceClassification,\n",
    "\tAutoTokenizer,\n",
    "\tBitsAndBytesConfig,\n",
    "\tTextStreamer,\n",
    "\tpipeline,\n",
    ")\n",
    "from unsloth import FastLanguageModel"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "7df2ec80ac934263",
   "metadata": {},
   "source": "## Load Each Module"
  },
  {
   "cell_type": "markdown",
   "id": "bbdd58114a803167",
   "metadata": {},
   "source": "### Response Generator"
  },
  {
   "cell_type": "code",
   "id": "4c80a1ee1d967a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:50.142668Z",
     "start_time": "2024-09-17T16:30:41.851166Z"
    }
   },
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "\tmodel_name=\"hermeschen1116/response_generator_for_emotion_chat_bot\",\n",
    "\tattn_implementation=\"flash_attention_2\",\n",
    "\tpretraining_tp=1,\n",
    "\tload_in_4bit=True,\n",
    "\tdevice_map=\"auto\",\n",
    "\tlow_cpu_mem_usage=True,\n",
    "\ttrust_remote_code=True,\n",
    ")\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.clean_up_tokenization_spaces = True"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth 2024.9: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3060. Max memory: 11.754 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "7d8c87bb53c02a3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:50.196435Z",
     "start_time": "2024-09-17T16:30:50.194689Z"
    }
   },
   "source": [
    "response_generator = ResponseGeneratorPipeline(\n",
    "\tmodel,\n",
    "\ttokenizer,\n",
    "\tframework=\"pt\",\n",
    "\ttask=\"conversation-generation\",\n",
    "\tnum_workers=16,\n",
    "\ttorch_dtype=\"auto\",\n",
    "\tadd_special_tokens=True,\n",
    "\ttruncation=False,\n",
    "\tpadding=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "10795eec37f51bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:50.242591Z",
     "start_time": "2024-09-17T16:30:50.240730Z"
    }
   },
   "source": [
    "FastLanguageModel.for_inference(response_generator.model)\n",
    "response_generator.model = torch.compile(response_generator.model)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "5e3a0f6986c4c83f",
   "metadata": {},
   "source": "### Sentiment Analyzer"
  },
  {
   "cell_type": "code",
   "id": "6e4e8f191cc8b3ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:50.739734Z",
     "start_time": "2024-09-17T16:30:50.284794Z"
    }
   },
   "source": [
    "sentiment_analysis_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\t\"Shotaro30678/sentiment_analysis_for_emotion_chat_bot\",\n",
    "\tquantization_config=BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16),\n",
    "\tdevice_map=\"auto\",\n",
    "\tlow_cpu_mem_usage=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "701fbd337943d5ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:51.023196Z",
     "start_time": "2024-09-17T16:30:50.746037Z"
    }
   },
   "source": [
    "sentiment_analysis_tokenizer = AutoTokenizer.from_pretrained(\n",
    "\t\"Shotaro30678/sentiment_analysis_for_emotion_chat_bot\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "bd6d594d260a8043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:51.033718Z",
     "start_time": "2024-09-17T16:30:51.031972Z"
    }
   },
   "source": [
    "sentiment_analyzer = pipeline(\n",
    "\t\"sentiment-analysis\",\n",
    "\tmodel=sentiment_analysis_model,\n",
    "\ttokenizer=sentiment_analysis_tokenizer,\n",
    "\ttop_k=7,\n",
    "\ttorch_dtype=torch.float32,\n",
    "\tdevice_map=\"auto\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9681c0078abce320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:51.079042Z",
     "start_time": "2024-09-17T16:30:51.077155Z"
    }
   },
   "source": [
    "sentiment_analyzer.model = torch.compile(sentiment_analyzer.model)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "5d0c90aa00097046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:51.130542Z",
     "start_time": "2024-09-17T16:30:51.128719Z"
    }
   },
   "source": [
    "print(sentiment_analyzer.model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "7b7f77a5a4fbf0e2",
   "metadata": {},
   "source": "### Emotion Predictor"
  },
  {
   "cell_type": "code",
   "id": "7c675bfb19becf6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:51.602895Z",
     "start_time": "2024-09-17T16:30:51.179634Z"
    }
   },
   "source": [
    "emotion_predictor_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\t\"Shotaro30678/emotion_predictor_for_emotion_chat_bot\",\n",
    "\tquantization_config=BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16),\n",
    "\tdevice_map=\"auto\",\n",
    "\tlow_cpu_mem_usage=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "b1d5b572b25d2871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:51.833438Z",
     "start_time": "2024-09-17T16:30:51.610959Z"
    }
   },
   "source": [
    "emotion_predictor_tokenizer = AutoTokenizer.from_pretrained(\n",
    "\t\"Shotaro30678/emotion_predictor_for_emotion_chat_bot\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "d3d609d13ac1305c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:51.846410Z",
     "start_time": "2024-09-17T16:30:51.844676Z"
    }
   },
   "source": [
    "emotion_predictor = pipeline(\n",
    "\t\"sentiment-analysis\",\n",
    "\tmodel=emotion_predictor_model,\n",
    "\ttokenizer=emotion_predictor_tokenizer,\n",
    "\ttop_k=7,\n",
    "\ttorch_dtype=torch.float32,\n",
    "\tdevice_map=\"auto\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "e83e581f580f9487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:51.890567Z",
     "start_time": "2024-09-17T16:30:51.888837Z"
    }
   },
   "source": [
    "emotion_predictor.model = torch.compile(emotion_predictor.model)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "f08b9c106afb713e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:51.934840Z",
     "start_time": "2024-09-17T16:30:51.932941Z"
    }
   },
   "source": [
    "print(emotion_predictor.model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "dceb3e74297ea1a9",
   "metadata": {},
   "source": "### Emotion Model"
  },
  {
   "cell_type": "code",
   "id": "8f257727afd216a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:52.436021Z",
     "start_time": "2024-09-17T16:30:51.979352Z"
    }
   },
   "source": [
    "emotion_model = EmotionModel.from_pretrained(\"hermeschen1116/emotion_model_for_emotion_chat_bot\")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "5420819fd9f588af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:52.448312Z",
     "start_time": "2024-09-17T16:30:52.446790Z"
    }
   },
   "source": [
    "emotion_model = torch.compile(emotion_model, mode=\"reduce-overhead\")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "4ee3d7ef2f38aeba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:52.491282Z",
     "start_time": "2024-09-17T16:30:52.489228Z"
    }
   },
   "source": [
    "print(emotion_model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): EmotionModel(\n",
      "    (_EmotionModel__weight_Q): Linear(in_features=7, out_features=7, bias=False)\n",
      "    (_EmotionModel__weight_K): Linear(in_features=7, out_features=7, bias=False)\n",
      "    (_EmotionModel__dropout): Dropout(p=0.5, inplace=False)\n",
      "    (_EmotionModel__weight_D): Linear(in_features=7, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "3614cf1c44cfd954",
   "metadata": {},
   "source": "### Similarity Analyzer"
  },
  {
   "cell_type": "code",
   "id": "d46904b2cf2ec820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:52.536730Z",
     "start_time": "2024-09-17T16:30:52.535261Z"
    }
   },
   "source": [
    "threshold: float = 0.5"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "35923cab42231bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:30:52.583287Z",
     "start_time": "2024-09-17T16:30:52.580691Z"
    }
   },
   "source": [
    "similarity_analyzer = EmotionPresentationSimilarityAnalyser(None, threshold=threshold)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "7812a7b3f8d2bb9b",
   "metadata": {},
   "source": "## Combine All Modules"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:41:49.260124Z",
     "start_time": "2024-09-17T16:41:49.258460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emotions: list = [\n",
    "\t\t\"neutral\",\n",
    "\t\t\"anger\",\n",
    "\t\t\"disgust\",\n",
    "\t\t\"fear\",\n",
    "\t\t\"happiness\",\n",
    "\t\t\"sadness\",\n",
    "\t\t\"surprise\",\n",
    "\t]"
   ],
   "id": "e6d48c0c4bcd7c0a",
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "6246f25cb03ad24b",
   "metadata": {},
   "source": "### Initialize"
  },
  {
   "cell_type": "code",
   "id": "a5bba438f3869366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:41:49.676810Z",
     "start_time": "2024-09-17T16:41:49.675177Z"
    }
   },
   "source": [
    "chat_buffer_size: int = 10"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "bbd8163729f358f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:41:49.881224Z",
     "start_time": "2024-09-17T16:41:49.879078Z"
    }
   },
   "source": [
    "logfile_uuid: uuid.UUID = uuid.uuid4()\n",
    "if not os.path.isdir(\"./logs\"):\n",
    "\tos.mkdir(\"./logs\")"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "1733c33e90049dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:41:50.096372Z",
     "start_time": "2024-09-17T16:41:50.094624Z"
    }
   },
   "source": [
    "streamer = TextStreamer(tokenizer, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "8e3e92093c478ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:42:01.652903Z",
     "start_time": "2024-09-17T16:42:01.650391Z"
    }
   },
   "source": [
    "bot_ideal_emotion_representation: Tensor = generate_dummy_representation(randint(0, 6))\n",
    "similarity_analyzer.ideal_emotion_representation = bot_ideal_emotion_representation\n",
    "dict(zip(emotions, bot_ideal_emotion_representation.tolist()))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0.3390445113182068,\n",
       " 'anger': 0.9162819385528564,\n",
       " 'disgust': 0.42804205417633057,\n",
       " 'fear': 0.5070522427558899,\n",
       " 'happiness': 0.448799192905426,\n",
       " 'sadness': 0.16032946109771729,\n",
       " 'surprise': 0.8833631873130798}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "a7fd1965488ecd1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:42:13.534485Z",
     "start_time": "2024-09-17T16:42:13.531786Z"
    }
   },
   "source": [
    "bot_emotion_representation: Tensor = generate_dummy_representation(randint(0, 6))\n",
    "bot_emotion_representation"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0489, 0.1856, 0.7903, 0.6453, 0.4324, 0.6348, 0.7582])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "322fc7f3cf905a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:42:15.984790Z",
     "start_time": "2024-09-17T16:42:13.984716Z"
    }
   },
   "source": [
    "system_prompt: str = input(\"Enter your system prompt: \").strip()\n",
    "bot_response: str = \"Talk to me...\""
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "8da454aae4c41c25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:42:17.124777Z",
     "start_time": "2024-09-17T16:42:17.123115Z"
    }
   },
   "source": [
    "chat_buffer: list = [{\"role\": \"system\", \"content\": {\"emotion\": \"\", \"dialog\": system_prompt}}]"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "38d2e521a8d16664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:42:17.956236Z",
     "start_time": "2024-09-17T16:42:17.954175Z"
    }
   },
   "source": [
    "chat_buffer"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': {'emotion': '', 'dialog': ''}}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "b5f10bbc9baa3309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T16:42:27.535182Z",
     "start_time": "2024-09-17T16:42:18.495147Z"
    }
   },
   "source": [
    "while True:\n",
    "\tuser_response: str = input(f\"Bot: {bot_response}\").strip()\n",
    "\tif user_response == \"quit\":\n",
    "\t\tbreak\n",
    "\n",
    "\tuser_emotion: list = sentiment_analyzer(user_response)[0]\n",
    "\tchat_buffer.append(\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": {\n",
    "\t\t\t\t\"emotion\": get_top_emotion(user_emotion),\n",
    "\t\t\t\t\"dialog\": user_response,\n",
    "\t\t\t},\n",
    "\t\t}\n",
    "\t)\n",
    "\n",
    "\tuser_emotion_composition: Tensor = get_sentiment_composition(user_emotion)\n",
    "\n",
    "\tbot_emotion_representation = emotion_model.forward(user_emotion_composition, bot_emotion_representation)\n",
    "\n",
    "\tbot_chat_simulations: list = []\n",
    "\twhile True:\n",
    "\t\tbot_chat_simulations = create_candidates_buffer(chat_buffer)\n",
    "\t\tbot_chat_simulations = [chat[0] for chat in response_generator(bot_chat_simulations, streamer=streamer)]\n",
    "\t\tprint()\n",
    "\t\twrite_log_file(logfile_uuid, bot_chat_simulations)\n",
    "\t\tbot_chat_simulations = list(filter(lambda chat: chat[-1][\"content\"][\"dialog\"] != \"\", bot_chat_simulations))\n",
    "\t\tif len(bot_chat_simulations) != 0:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tbot_response_simulations: list = [chat[-1][\"content\"] for chat in bot_chat_simulations]\n",
    "\n",
    "\tuser_future_emotion_composition_simulations: dict = {\n",
    "\t\tresponse[\"emotion\"]: get_sentiment_composition(emotion_predictor(response[\"dialog\"])[0])\n",
    "\t\tfor response in bot_response_simulations\n",
    "\t}\n",
    "\n",
    "\tbot_future_emotion_representations: dict = {\n",
    "\t\tk: emotion_model.forward(v, bot_emotion_representation)\n",
    "\t\tfor k, v in user_future_emotion_composition_simulations.items()\n",
    "\t}\n",
    "\n",
    "\temotion_representation_similarity_scores: list = similarity_analyzer(\n",
    "\t\ttorch.stack(list(bot_future_emotion_representations.values())),\n",
    "\t)\n",
    "\n",
    "\tcandidate_emotion_index: int = torch.argmax(emotion_representation_similarity_scores).item()\n",
    "\tbot_best_response_emotion: str = emotions[candidate_emotion_index]\n",
    "\n",
    "\tif len(chat_buffer) == chat_buffer_size + 1:\n",
    "\t\tchat_buffer.pop(1)\n",
    "\tchat_buffer.append({\"role\": \"bot\", \"content\": {\"emotion\": bot_best_response_emotion, \"dialog\": \"\"}})\n",
    "\n",
    "\tchat_buffer = response_generator(chat_buffer, streamer=streamer)[0]\n",
    "\tprint()\n",
    "\tif chat_buffer[-1][\"content\"][\"dialog\"] == \"\":\n",
    "\t\tchat_buffer[-1][\"content\"][\"dialog\"] = bot_response_simulations[candidate_emotion_index][\"dialog\"]\n",
    "\tbot_response = chat_buffer[-1][\"content\"][\"dialog\"]\n",
    "\twrite_log_file(logfile_uuid, chat_buffer)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m user_response \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquit\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m      4\u001B[0m \t\u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m user_emotion: \u001B[38;5;28mlist\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43msentiment_analyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_response\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      7\u001B[0m chat_buffer\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m      8\u001B[0m \t{\n\u001B[1;32m      9\u001B[0m \t\t\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m \t}\n\u001B[1;32m     15\u001B[0m )\n\u001B[1;32m     17\u001B[0m user_emotion_composition: Tensor \u001B[38;5;241m=\u001B[39m get_sentiment_composition(user_emotion)\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:156\u001B[0m, in \u001B[0;36mTextClassificationPipeline.__call__\u001B[0;34m(self, inputs, **kwargs)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;124;03mClassify the text(s) given as inputs.\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    155\u001B[0m inputs \u001B[38;5;241m=\u001B[39m (inputs,)\n\u001B[0;32m--> 156\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001B[39;00m\n\u001B[1;32m    158\u001B[0m _legacy \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_k\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1257\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1249\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[1;32m   1250\u001B[0m         \u001B[38;5;28miter\u001B[39m(\n\u001B[1;32m   1251\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1254\u001B[0m         )\n\u001B[1;32m   1255\u001B[0m     )\n\u001B[1;32m   1256\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1257\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1264\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[1;32m   1263\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[0;32m-> 1264\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[1;32m   1266\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1164\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[0;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[1;32m   1162\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[1;32m   1163\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m-> 1164\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1165\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:187\u001B[0m, in \u001B[0;36mTextClassificationPipeline._forward\u001B[0;34m(self, model_inputs)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(model_forward)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    186\u001B[0m     model_inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m--> 187\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:433\u001B[0m, in \u001B[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    428\u001B[0m saved_dynamic_layer_stack_depth \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    429\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_functorch\u001B[38;5;241m.\u001B[39mget_dynamic_layer_stack_depth()\n\u001B[1;32m    430\u001B[0m )\n\u001B[1;32m    432\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    435\u001B[0m     \u001B[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001B[39;00m\n\u001B[1;32m    436\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_functorch\u001B[38;5;241m.\u001B[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001B[1;32m    437\u001B[0m         saved_dynamic_layer_stack_depth\n\u001B[1;32m    438\u001B[0m     )\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/accelerate/hooks.py:165\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnew_forward\u001B[39m(module, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 165\u001B[0m     args, kwargs \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpre_forward(module, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mno_grad:\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/accelerate/hooks.py:170\u001B[0m, in \u001B[0;36mtorch_dynamo_resume_in_new_forward_at_165\u001B[0;34m(___stack0, module)\u001B[0m\n\u001B[1;32m    168\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 170\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:1166\u001B[0m, in \u001B[0;36mRobertaForSequenceClassification.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1163\u001B[0m     \u001B[38;5;66;03m# Initialize weights and apply final processing\u001B[39;00m\n\u001B[1;32m   1164\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_init()\n\u001B[0;32m-> 1166\u001B[0m \u001B[38;5;129m@add_start_docstrings_to_model_forward\u001B[39m(ROBERTA_INPUTS_DOCSTRING\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size, sequence_length\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m   1167\u001B[0m \u001B[38;5;129m@add_code_sample_docstrings\u001B[39m(\n\u001B[1;32m   1168\u001B[0m     checkpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcardiffnlp/twitter-roberta-base-emotion\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1169\u001B[0m     output_type\u001B[38;5;241m=\u001B[39mSequenceClassifierOutput,\n\u001B[1;32m   1170\u001B[0m     config_class\u001B[38;5;241m=\u001B[39m_CONFIG_FOR_DOC,\n\u001B[1;32m   1171\u001B[0m     expected_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moptimism\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1172\u001B[0m     expected_loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.08\u001B[39m,\n\u001B[1;32m   1173\u001B[0m )\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m   1175\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1176\u001B[0m     input_ids: Optional[torch\u001B[38;5;241m.\u001B[39mLongTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1177\u001B[0m     attention_mask: Optional[torch\u001B[38;5;241m.\u001B[39mFloatTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1178\u001B[0m     token_type_ids: Optional[torch\u001B[38;5;241m.\u001B[39mLongTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1179\u001B[0m     position_ids: Optional[torch\u001B[38;5;241m.\u001B[39mLongTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1180\u001B[0m     head_mask: Optional[torch\u001B[38;5;241m.\u001B[39mFloatTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1181\u001B[0m     inputs_embeds: Optional[torch\u001B[38;5;241m.\u001B[39mFloatTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1182\u001B[0m     labels: Optional[torch\u001B[38;5;241m.\u001B[39mLongTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1183\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1184\u001B[0m     output_hidden_states: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1185\u001B[0m     return_dict: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1186\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[Tuple[torch\u001B[38;5;241m.\u001B[39mTensor], SequenceClassifierOutput]:\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;124;03m    labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1189\u001B[0m \u001B[38;5;124;03m        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;124;03m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;124;03m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1193\u001B[0m     return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/accelerate/hooks.py:165\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnew_forward\u001B[39m(module, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 165\u001B[0m     args, kwargs \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpre_forward(module, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mno_grad:\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/accelerate/hooks.py:170\u001B[0m, in \u001B[0;36mtorch_dynamo_resume_in_new_forward_at_165\u001B[0;34m(___stack0, module)\u001B[0m\n\u001B[1;32m    168\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 170\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:722\u001B[0m, in \u001B[0;36mRobertaModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    719\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m layer, heads \u001B[38;5;129;01min\u001B[39;00m heads_to_prune\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    720\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder\u001B[38;5;241m.\u001B[39mlayer[layer]\u001B[38;5;241m.\u001B[39mattention\u001B[38;5;241m.\u001B[39mprune_heads(heads)\n\u001B[0;32m--> 722\u001B[0m \u001B[38;5;129m@add_start_docstrings_to_model_forward\u001B[39m(ROBERTA_INPUTS_DOCSTRING\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size, sequence_length\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    723\u001B[0m \u001B[38;5;129m@add_code_sample_docstrings\u001B[39m(\n\u001B[1;32m    724\u001B[0m     checkpoint\u001B[38;5;241m=\u001B[39m_CHECKPOINT_FOR_DOC,\n\u001B[1;32m    725\u001B[0m     output_type\u001B[38;5;241m=\u001B[39mBaseModelOutputWithPoolingAndCrossAttentions,\n\u001B[1;32m    726\u001B[0m     config_class\u001B[38;5;241m=\u001B[39m_CONFIG_FOR_DOC,\n\u001B[1;32m    727\u001B[0m )\n\u001B[1;32m    728\u001B[0m \u001B[38;5;66;03m# Copied from transformers.models.clap.modeling_clap.ClapTextModel.forward\u001B[39;00m\n\u001B[1;32m    729\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    730\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    731\u001B[0m     input_ids: Optional[torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    732\u001B[0m     attention_mask: Optional[torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    733\u001B[0m     token_type_ids: Optional[torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    734\u001B[0m     position_ids: Optional[torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    735\u001B[0m     head_mask: Optional[torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    736\u001B[0m     inputs_embeds: Optional[torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    737\u001B[0m     encoder_hidden_states: Optional[torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    738\u001B[0m     encoder_attention_mask: Optional[torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    739\u001B[0m     past_key_values: Optional[List[torch\u001B[38;5;241m.\u001B[39mFloatTensor]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    740\u001B[0m     use_cache: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    741\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    742\u001B[0m     output_hidden_states: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    743\u001B[0m     return_dict: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    744\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[Tuple[torch\u001B[38;5;241m.\u001B[39mTensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n\u001B[1;32m    745\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    746\u001B[0m \u001B[38;5;124;03m    encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\u001B[39;00m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;124;03m        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    763\u001B[0m \u001B[38;5;124;03m        `past_key_values`).\u001B[39;00m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    765\u001B[0m     output_attentions \u001B[38;5;241m=\u001B[39m output_attentions \u001B[38;5;28;01mif\u001B[39;00m output_attentions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39moutput_attentions\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:805\u001B[0m, in \u001B[0;36mtorch_dynamo_resume_in_forward_at_805\u001B[0;34m(___stack0, self, input_ids, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, device, past_key_values_length)\u001B[0m\n\u001B[1;32m    801\u001B[0m         token_type_ids \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(input_shape, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m    803\u001B[0m \u001B[38;5;66;03m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001B[39;00m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;66;03m# ourselves in which case we just need to make it broadcastable to all heads.\u001B[39;00m\n\u001B[0;32m--> 805\u001B[0m extended_attention_mask: torch\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_extended_attention_mask(attention_mask, input_shape)\n\u001B[1;32m    807\u001B[0m \u001B[38;5;66;03m# If a 2D or 3D attention mask is provided for the cross-attention\u001B[39;00m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;66;03m# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\u001B[39;00m\n\u001B[1;32m    809\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_decoder \u001B[38;5;129;01mand\u001B[39;00m encoder_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:825\u001B[0m, in \u001B[0;36mtorch_dynamo_resume_in_forward_at_825\u001B[0;34m(___stack0, self, head_mask, encoder_hidden_states, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, extended_attention_mask, encoder_extended_attention_mask)\u001B[0m\n\u001B[1;32m    818\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[1;32m    819\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[1;32m    820\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[1;32m    821\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[1;32m    822\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[1;32m    823\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m--> 825\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[1;32m    826\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m    827\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m    828\u001B[0m     token_type_ids\u001B[38;5;241m=\u001B[39mtoken_type_ids,\n\u001B[1;32m    829\u001B[0m     inputs_embeds\u001B[38;5;241m=\u001B[39minputs_embeds,\n\u001B[1;32m    830\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[1;32m    831\u001B[0m )\n\u001B[1;32m    832\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[1;32m    833\u001B[0m     embedding_output,\n\u001B[1;32m    834\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mextended_attention_mask,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    842\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m    843\u001B[0m )\n\u001B[1;32m    844\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/accelerate/hooks.py:165\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnew_forward\u001B[39m(module, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 165\u001B[0m     args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_hf_hook\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpre_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mno_grad:\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/accelerate/hooks.py:323\u001B[0m, in \u001B[0;36mAlignDevicesHook.pre_forward\u001B[0;34m(self, module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m                 set_module_tensor_to_device(\n\u001B[1;32m    318\u001B[0m                     module, name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexecution_device, tied_params_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtied_params_map\n\u001B[1;32m    319\u001B[0m                 )\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m module\n\u001B[0;32m--> 323\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpre_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, module, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    324\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mio_same_device:\n\u001B[1;32m    325\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_device \u001B[38;5;241m=\u001B[39m find_device([args, kwargs])\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py:185\u001B[0m, in \u001B[0;36msend_to_device\u001B[0;34m(tensor, device, non_blocking, skip_keys)\u001B[0m\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m skip_keys \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    182\u001B[0m         skip_keys \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(tensor)(\n\u001B[1;32m    184\u001B[0m         {\n\u001B[0;32m--> 185\u001B[0m             k: t \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m skip_keys \u001B[38;5;28;01melse\u001B[39;00m \u001B[43msend_to_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_keys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m k, t \u001B[38;5;129;01min\u001B[39;00m tensor\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m    187\u001B[0m         }\n\u001B[1;32m    188\u001B[0m     )\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tensor\n",
      "File \u001B[0;32m<string>:42\u001B[0m, in \u001B[0;36m_fixed_send_to_device\u001B[0;34m(tensor, device, non_blocking, skip_keys)\u001B[0m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py:82\u001B[0m, in \u001B[0;36mhonor_type\u001B[0;34m(obj, generator)\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(obj)(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlist\u001B[39m(generator))\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 82\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<string>:43\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'str' object is not callable"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "5dd66746b625fef4",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
