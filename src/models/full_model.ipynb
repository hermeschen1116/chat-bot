{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3ca6205fd0c59f",
   "metadata": {},
   "source": "# Emotion Chat Bot"
  },
  {
   "cell_type": "code",
   "id": "1a2aa4f1318f3251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:15.656931Z",
     "start_time": "2024-09-17T15:43:12.874377Z"
    }
   },
   "source": [
    "import os.path\n",
    "import uuid\n",
    "\n",
    "import torch\n",
    "from libs import (\n",
    "\tEmotionModel,\n",
    "\tEmotionPresentationSimilarityAnalyser,\n",
    "\tResponseGeneratorPipeline,\n",
    "\tgenerate_dummy_representation,\n",
    "\tget_sentiment_composition,\n",
    ")\n",
    "from libs.FullModel import create_candidates_buffer, get_top_emotion, write_log_file\n",
    "from sympy.core.random import randint\n",
    "from torch import Tensor\n",
    "from transformers import (\n",
    "\tAutoModelForSequenceClassification,\n",
    "\tAutoTokenizer,\n",
    "\tBitsAndBytesConfig,\n",
    "\tTextStreamer,\n",
    "\tpipeline,\n",
    ")\n",
    "from unsloth import FastLanguageModel"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "7df2ec80ac934263",
   "metadata": {},
   "source": "## Load Each Module"
  },
  {
   "cell_type": "markdown",
   "id": "bbdd58114a803167",
   "metadata": {},
   "source": "### Response Generator"
  },
  {
   "cell_type": "code",
   "id": "4c80a1ee1d967a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:28.461735Z",
     "start_time": "2024-09-17T15:43:15.663830Z"
    }
   },
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "\tmodel_name=\"hermeschen1116/response_generator_for_emotion_chat_bot\",\n",
    "\tattn_implementation=\"flash_attention_2\",\n",
    "\tpretraining_tp=1,\n",
    "\tload_in_4bit=True,\n",
    "\tdevice_map=\"auto\",\n",
    "\tlow_cpu_mem_usage=True,\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth 2024.9: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3060. Max memory: 11.754 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "7d8c87bb53c02a3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:28.514506Z",
     "start_time": "2024-09-17T15:43:28.512801Z"
    }
   },
   "source": [
    "response_generator = ResponseGeneratorPipeline(\n",
    "\tmodel,\n",
    "\ttokenizer,\n",
    "\tframework=\"pt\",\n",
    "\ttask=\"conversation-generation\",\n",
    "\tnum_workers=16,\n",
    "\ttorch_dtype=\"auto\",\n",
    "\tadd_special_tokens=True,\n",
    "\ttruncation=False,\n",
    "\tpadding=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "10795eec37f51bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:28.559068Z",
     "start_time": "2024-09-17T15:43:28.557074Z"
    }
   },
   "source": [
    "FastLanguageModel.for_inference(response_generator.model)\n",
    "response_generator.model = torch.compile(response_generator.model, mode=\"reduce-overhead\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "5e3a0f6986c4c83f",
   "metadata": {},
   "source": "### Sentiment Analyzer"
  },
  {
   "cell_type": "code",
   "id": "6e4e8f191cc8b3ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:29.035576Z",
     "start_time": "2024-09-17T15:43:28.600906Z"
    }
   },
   "source": [
    "sentiment_analysis_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\t\"Shotaro30678/sentiment_analysis_for_emotion_chat_bot\",\n",
    "\tquantization_config=BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16),\n",
    "\tdevice_map=\"auto\",\n",
    "\tlow_cpu_mem_usage=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "701fbd337943d5ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:29.269444Z",
     "start_time": "2024-09-17T15:43:29.041987Z"
    }
   },
   "source": [
    "sentiment_analysis_tokenizer = AutoTokenizer.from_pretrained(\n",
    "\t\"Shotaro30678/sentiment_analysis_for_emotion_chat_bot\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "bd6d594d260a8043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:29.279231Z",
     "start_time": "2024-09-17T15:43:29.277703Z"
    }
   },
   "source": [
    "sentiment_analyzer = pipeline(\n",
    "\t\"sentiment-analysis\",\n",
    "\tmodel=sentiment_analysis_model,\n",
    "\ttokenizer=sentiment_analysis_tokenizer,\n",
    "\ttop_k=7,\n",
    "\ttorch_dtype=torch.float32,\n",
    "\tdevice_map=\"auto\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9681c0078abce320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:29.322852Z",
     "start_time": "2024-09-17T15:43:29.320975Z"
    }
   },
   "source": [
    "sentiment_analyzer.model = torch.compile(sentiment_analyzer.model, mode=\"reduce-overhead\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "5d0c90aa00097046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:29.369196Z",
     "start_time": "2024-09-17T15:43:29.367225Z"
    }
   },
   "source": [
    "print(sentiment_analyzer.model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "7b7f77a5a4fbf0e2",
   "metadata": {},
   "source": "### Emotion Predictor"
  },
  {
   "cell_type": "code",
   "id": "7c675bfb19becf6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:29.834560Z",
     "start_time": "2024-09-17T15:43:29.415180Z"
    }
   },
   "source": [
    "emotion_predictor_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\t\"Shotaro30678/emotion_predictor_for_emotion_chat_bot\",\n",
    "\tquantization_config=BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16),\n",
    "\tdevice_map=\"auto\",\n",
    "\tlow_cpu_mem_usage=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "b1d5b572b25d2871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.061340Z",
     "start_time": "2024-09-17T15:43:29.843131Z"
    }
   },
   "source": [
    "emotion_predictor_tokenizer = AutoTokenizer.from_pretrained(\n",
    "\t\"Shotaro30678/emotion_predictor_for_emotion_chat_bot\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "d3d609d13ac1305c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.073742Z",
     "start_time": "2024-09-17T15:43:30.072145Z"
    }
   },
   "source": [
    "emotion_predictor = pipeline(\n",
    "\t\"sentiment-analysis\",\n",
    "\tmodel=emotion_predictor_model,\n",
    "\ttokenizer=emotion_predictor_tokenizer,\n",
    "\ttop_k=7,\n",
    "\ttorch_dtype=torch.float32,\n",
    "\tdevice_map=\"auto\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "e83e581f580f9487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.119084Z",
     "start_time": "2024-09-17T15:43:30.117094Z"
    }
   },
   "source": [
    "emotion_predictor.model = torch.compile(emotion_predictor.model, mode=\"reduce-overhead\")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "f08b9c106afb713e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.164988Z",
     "start_time": "2024-09-17T15:43:30.162986Z"
    }
   },
   "source": [
    "print(emotion_predictor.model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "dceb3e74297ea1a9",
   "metadata": {},
   "source": "### Emotion Model"
  },
  {
   "cell_type": "code",
   "id": "8f257727afd216a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.615813Z",
     "start_time": "2024-09-17T15:43:30.211180Z"
    }
   },
   "source": [
    "emotion_model = EmotionModel.from_pretrained(\"hermeschen1116/emotion_model_for_emotion_chat_bot\")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "5420819fd9f588af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.661175Z",
     "start_time": "2024-09-17T15:43:30.658893Z"
    }
   },
   "source": [
    "emotion_model = torch.compile(emotion_model, mode=\"reduce-overhead\")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "4ee3d7ef2f38aeba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.714171Z",
     "start_time": "2024-09-17T15:43:30.712268Z"
    }
   },
   "source": [
    "print(emotion_model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): EmotionModel(\n",
      "    (_EmotionModel__weight_Q): Linear(in_features=7, out_features=7, bias=False)\n",
      "    (_EmotionModel__weight_K): Linear(in_features=7, out_features=7, bias=False)\n",
      "    (_EmotionModel__dropout): Dropout(p=0.5, inplace=False)\n",
      "    (_EmotionModel__weight_D): Linear(in_features=7, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "3614cf1c44cfd954",
   "metadata": {},
   "source": "### Similarity Analyzer"
  },
  {
   "cell_type": "code",
   "id": "d46904b2cf2ec820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.766641Z",
     "start_time": "2024-09-17T15:43:30.764822Z"
    }
   },
   "source": [
    "threshold: float = 0.5"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "35923cab42231bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.811061Z",
     "start_time": "2024-09-17T15:43:30.809334Z"
    }
   },
   "source": [
    "similarity_analyzer = EmotionPresentationSimilarityAnalyser(None, threshold=threshold)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "7812a7b3f8d2bb9b",
   "metadata": {},
   "source": "## Combine All Modules"
  },
  {
   "cell_type": "markdown",
   "id": "6246f25cb03ad24b",
   "metadata": {},
   "source": "### Initialize"
  },
  {
   "cell_type": "code",
   "id": "a5bba438f3869366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.864451Z",
     "start_time": "2024-09-17T15:43:30.862612Z"
    }
   },
   "source": [
    "chat_buffer_size: int = 10"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "bbd8163729f358f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.911382Z",
     "start_time": "2024-09-17T15:43:30.909476Z"
    }
   },
   "source": [
    "logfile_uuid: uuid.UUID = uuid.uuid4()\n",
    "if not os.path.isdir(\"./logs\"):\n",
    "\tos.mkdir(\"./logs\")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "1733c33e90049dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:30.958631Z",
     "start_time": "2024-09-17T15:43:30.956960Z"
    }
   },
   "source": [
    "streamer = TextStreamer(tokenizer, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "8e3e92093c478ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:31.006319Z",
     "start_time": "2024-09-17T15:43:31.001998Z"
    }
   },
   "source": [
    "bot_ideal_emotion_representation: Tensor = generate_dummy_representation(randint(0, 6))\n",
    "similarity_analyzer.ideal_emotion_representation = bot_ideal_emotion_representation\n",
    "bot_ideal_emotion_representation"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9055, 0.0484, 0.2106, 0.5950, 0.4134, 0.7965, 0.7471])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "a7fd1965488ecd1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:31.109646Z",
     "start_time": "2024-09-17T15:43:31.106528Z"
    }
   },
   "source": [
    "bot_emotion_representation: Tensor = generate_dummy_representation(randint(0, 6))\n",
    "bot_emotion_representation"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8843, 0.4715, 0.1718, 0.4886, 0.2030, 0.7743, 0.4018])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "322fc7f3cf905a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:37.413931Z",
     "start_time": "2024-09-17T15:43:31.208585Z"
    }
   },
   "source": [
    "system_prompt: str = input(\"Enter your system prompt: \").strip()\n",
    "bot_message: str = \"Talk to me...\""
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "8da454aae4c41c25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:37.432330Z",
     "start_time": "2024-09-17T15:43:37.430587Z"
    }
   },
   "source": [
    "chat_buffer: list = [{\"role\": \"system\", \"content\": {\"emotion\": \"\", \"dialog\": system_prompt}}]"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "38d2e521a8d16664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:43:37.480008Z",
     "start_time": "2024-09-17T15:43:37.477958Z"
    }
   },
   "source": [
    "chat_buffer"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': {'emotion': '', 'dialog': ''}}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "b5f10bbc9baa3309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T15:44:35.343135Z",
     "start_time": "2024-09-17T15:43:37.528602Z"
    }
   },
   "source": [
    "while True:\n",
    "\tuser_response: str = input(f\"Bot: {bot_message}\").strip()\n",
    "\tif user_response == \"quit\":\n",
    "\t\tbreak\n",
    "\n",
    "\tuser_emotion: list = sentiment_analyzer(user_response)\n",
    "\tchat_buffer.append(\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": {\n",
    "\t\t\t\t\"emotion\": get_top_emotion(user_emotion),\n",
    "\t\t\t\t\"dialog\": user_response,\n",
    "\t\t\t},\n",
    "\t\t}\n",
    "\t)\n",
    "\n",
    "\tuser_emotion_composition: Tensor = get_sentiment_composition(user_emotion)\n",
    "\n",
    "\tbot_emotion_representation = emotion_model.forward(user_emotion_composition, bot_emotion_representation)\n",
    "\n",
    "\tbot_chat_simulations: list = []\n",
    "\twhile True:\n",
    "\t\tbot_chat_simulations = create_candidates_buffer(chat_buffer)\n",
    "\t\tbot_chat_simulations = [chat[0] for chat in response_generator(bot_chat_simulations, streamer=streamer)]\n",
    "\t\tprint()\n",
    "\t\twrite_log_file(logfile_uuid, bot_chat_simulations)\n",
    "\t\tbot_chat_simulations = list(filter(lambda chat: chat[-1][\"content\"][\"dialog\"] != \"\", bot_chat_simulations))\n",
    "\t\tif len(bot_chat_simulations) != 0:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tbot_response_simulations: list = [chat[-1][\"content\"] for chat in bot_chat_simulations]\n",
    "\n",
    "\tuser_future_emotion_composition_simulations: dict = {\n",
    "\t\tresponse[\"emotion\"]: get_sentiment_composition(emotion_predictor(response[\"dialog\"]))\n",
    "\t\tfor response in bot_response_simulations\n",
    "\t}\n",
    "\n",
    "\tbot_future_emotion_representations: dict = {\n",
    "\t\tk: emotion_model.forward(v, bot_emotion_representation)\n",
    "\t\tfor k, v in user_future_emotion_composition_simulations.items()\n",
    "\t}\n",
    "\n",
    "\temotion_representation_similarity_scores: list = similarity_analyzer(\n",
    "\t\ttorch.stack(list(bot_future_emotion_representations.values())),\n",
    "\t)\n",
    "\n",
    "\temotions: list = [\n",
    "\t\t\"neutral\",\n",
    "\t\t\"anger\",\n",
    "\t\t\"disgust\",\n",
    "\t\t\"fear\",\n",
    "\t\t\"happiness\",\n",
    "\t\t\"sadness\",\n",
    "\t\t\"surprise\",\n",
    "\t]\n",
    "\tcandidate_emotion_index: int = torch.argmax(emotion_representation_similarity_scores).item()\n",
    "\tbot_best_response_emotion: str = emotions[candidate_emotion_index]\n",
    "\n",
    "\tif len(chat_buffer) == chat_buffer_size + 1:\n",
    "\t\tchat_buffer.pop(1)\n",
    "\tchat_buffer.append({\"role\": \"bot\", \"content\": {\"emotion\": bot_best_response_emotion, \"dialog\": \"\"}})\n",
    "\n",
    "\tchat_buffer = response_generator(chat_buffer, streamer=streamer)[0]\n",
    "\tprint()\n",
    "\tif chat_buffer[-1][\"content\"][\"dialog\"] == \"\":\n",
    "\t\tchat_buffer[-1][\"content\"][\"dialog\"] = bot_chat_simulations[candidate_emotion_index][\"dialog\"]\n",
    "\tbot_message = chat_buffer[-1][\"content\"][\"dialog\"]\n",
    "\twrite_log_file(logfile_uuid, chat_buffer)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping cudagraphs due to mutated inputs (1 instances). Found from : \n",
      "   File \"/home/hermeschen/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py\", line 121, in torch_dynamo_resume_in_forward_at_120\n",
      "    embeddings += position_embeddings\n",
      "\n",
      "skipping cudagraphs due to mutated inputs (1 instances). Found from : \n",
      "   File \"/home/hermeschen/Repo/chat-bot/.venv/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py\", line 576, in torch_dynamo_resume_in_matmul_4bit_at_574\n",
      "    out += bias\n",
      "\n",
      "skipping cudagraphs due to skipping cudagraphs due to cpu device (primals_5). Found from : \n",
      "   File \"/home/hermeschen/Repo/chat-bot/src/models/libs/EmotionModel.py\", line 36, in forward\n",
      "    decomposed_representation: Tensor = representation.diag().to(dtype=self.__dtype, device=self.__device)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   neutral   Hello, how are you?     neutral    Fine, and you? \n",
      "   neutral   Hello, how are you?     anger    Hi! I'm fine! \n",
      "   neutral   Hello, how are you?     disgust    disgust   I'm not very well. I'm not feeling at all well. \n",
      "   neutral   Hello, how are you?     fear    Hi! I'm terribly nervous. \n",
      "   neutral   Hello, how are you?     happiness     Fine, thanks. \n",
      "   neutral   Hello, how are you?     sadness   \n",
      "   neutral   Hello, how are you?     surprise   \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping cudagraphs due to mutated inputs (1 instances). Found from : \n",
      "   File \"/home/hermeschen/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py\", line 121, in torch_dynamo_resume_in_forward_at_120\n",
      "    embeddings += position_embeddings\n",
      "\n",
      "skipping cudagraphs due to skipping cudagraphs due to cpu device (primals_5). Found from : \n",
      "   File \"/home/hermeschen/Repo/chat-bot/src/models/libs/EmotionModel.py\", line 36, in forward\n",
      "    decomposed_representation: Tensor = representation.diag().to(dtype=self.__dtype, device=self.__device)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   neutral   Hello, how are you?     fear    Hi, I'm scared. \n",
      "\n",
      "   neutral   Hello, how are you?     fear   Hi, I'm scared.  \n",
      "    neutral   Why? I just want to be friendly.     neutral   \n",
      "   neutral   Hello, how are you?     fear   Hi, I'm scared.  \n",
      "    neutral   Why? I just want to be friendly.     anger   \n",
      "   neutral   Hello, how are you?     fear   Hi, I'm scared.  \n",
      "    neutral   Why? I just want to be friendly.     disgust   \n",
      "   neutral   Hello, how are you?     fear   Hi, I'm scared.  \n",
      "    neutral   Why? I just want to be friendly.     fear   \n",
      "   neutral   Hello, how are you?     fear   Hi, I'm scared.  \n",
      "    neutral   Why? I just want to be friendly.     happiness     That's nice of you. \n",
      "   neutral   Hello, how are you?     fear   Hi, I'm scared.  \n",
      "    neutral   Why? I just want to be friendly.     sadness   \n",
      "   neutral   Hello, how are you?     fear   Hi, I'm scared.  \n",
      "    neutral   Why? I just want to be friendly.     surprise   \n",
      "\n",
      "   neutral   Hello, how are you?     fear   Hi, I'm scared.  \n",
      "    neutral   Why? I just want to be friendly.     neutral   \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 66\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28mprint\u001B[39m()\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chat_buffer[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdialog\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 66\u001B[0m \tchat_buffer[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdialog\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mbot_chat_simulations\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcandidate_emotion_index\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdialog\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     67\u001B[0m bot_message \u001B[38;5;241m=\u001B[39m chat_buffer[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdialog\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     68\u001B[0m write_log_file(logfile_uuid, chat_buffer)\n",
      "\u001B[0;31mTypeError\u001B[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd66746b625fef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
