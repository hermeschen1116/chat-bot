{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3ca6205fd0c59f",
   "metadata": {},
   "source": "# Emotion Chat Bot"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a2aa4f1318f3251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:41.636822Z",
     "start_time": "2024-09-17T08:35:38.944341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from libs import (\n",
    "    EmotionModel,\n",
    "    ResponseGeneratorPipeline,\n",
    "    SimilarityAnalyser,\n",
    "    generate_dummy_representation,\n",
    "    get_sentiment_composition,\n",
    ")\n",
    "from libs.FullModel import (\n",
    "    ChatMessage,\n",
    "    create_candidates_buffer,\n",
    "    get_possible_response_emotion_representation,\n",
    "    get_top_emotion,\n",
    ")\n",
    "from sympy.core.random import randint\n",
    "from torch import Tensor\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TextStreamer,\n",
    "    pipeline,\n",
    ")\n",
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df2ec80ac934263",
   "metadata": {},
   "source": "## Load Each Module"
  },
  {
   "cell_type": "markdown",
   "id": "bbdd58114a803167",
   "metadata": {},
   "source": "### Response Generator"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c80a1ee1d967a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:48.966654Z",
     "start_time": "2024-09-17T08:35:41.655744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth 2024.9: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3060. Max memory: 11.754 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"hermeschen1116/response_generator_for_emotion_chat_bot\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    pretraining_tp=1,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8c87bb53c02a3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:49.020260Z",
     "start_time": "2024-09-17T08:35:49.018733Z"
    }
   },
   "outputs": [],
   "source": [
    "response_generator = ResponseGeneratorPipeline(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    framework=\"pt\",\n",
    "    task=\"conversation-generation\",\n",
    "    num_workers=16,\n",
    "    torch_dtype=\"auto\",\n",
    "    add_special_tokens=True,\n",
    "    truncation=False,\n",
    "    padding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10795eec37f51bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:49.062917Z",
     "start_time": "2024-09-17T08:35:49.061013Z"
    }
   },
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(response_generator.model)\n",
    "response_generator.model = torch.compile(\n",
    "    response_generator.model, mode=\"reduce-overhead\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a0f6986c4c83f",
   "metadata": {},
   "source": "### Sentiment Analyzer"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4e8f191cc8b3ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:49.578259Z",
     "start_time": "2024-09-17T08:35:49.104863Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_analysis_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"Shotaro30678/sentiment_analysis_for_emotion_chat_bot\",\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16\n",
    "    ),\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "701fbd337943d5ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:49.810278Z",
     "start_time": "2024-09-17T08:35:49.584518Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_analysis_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Shotaro30678/sentiment_analysis_for_emotion_chat_bot\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd6d594d260a8043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:49.820307Z",
     "start_time": "2024-09-17T08:35:49.818625Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=sentiment_analysis_model,\n",
    "    tokenizer=sentiment_analysis_tokenizer,\n",
    "    top_k=7,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9681c0078abce320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:49.862925Z",
     "start_time": "2024-09-17T08:35:49.861035Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_analyzer.model = torch.compile(\n",
    "    sentiment_analyzer.model, mode=\"reduce-overhead\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d0c90aa00097046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:49.911921Z",
     "start_time": "2024-09-17T08:35:49.909433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_analyzer.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7f77a5a4fbf0e2",
   "metadata": {},
   "source": "### Emotion Predictor"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c675bfb19becf6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:50.378123Z",
     "start_time": "2024-09-17T08:35:49.960703Z"
    }
   },
   "outputs": [],
   "source": [
    "emotion_predictor_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"Shotaro30678/emotion_predictor_for_emotion_chat_bot\",\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16\n",
    "    ),\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d5b572b25d2871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:50.604135Z",
     "start_time": "2024-09-17T08:35:50.387029Z"
    }
   },
   "outputs": [],
   "source": [
    "emotion_predictor_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Shotaro30678/emotion_predictor_for_emotion_chat_bot\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d609d13ac1305c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:50.616513Z",
     "start_time": "2024-09-17T08:35:50.614886Z"
    }
   },
   "outputs": [],
   "source": [
    "emotion_predictor = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=emotion_predictor_model,\n",
    "    tokenizer=emotion_predictor_tokenizer,\n",
    "    top_k=7,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e83e581f580f9487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:50.659312Z",
     "start_time": "2024-09-17T08:35:50.657419Z"
    }
   },
   "outputs": [],
   "source": [
    "emotion_predictor.model = torch.compile(emotion_predictor.model, mode=\"reduce-overhead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f08b9c106afb713e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:50.711084Z",
     "start_time": "2024-09-17T08:35:50.709075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(emotion_predictor.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb3e74297ea1a9",
   "metadata": {},
   "source": "### Emotion Model"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f257727afd216a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.192026Z",
     "start_time": "2024-09-17T08:35:50.756461Z"
    }
   },
   "outputs": [],
   "source": [
    "emotion_model = EmotionModel.from_pretrained(\n",
    "    \"hermeschen1116/emotion_model_for_emotion_chat_bot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5420819fd9f588af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.204731Z",
     "start_time": "2024-09-17T08:35:51.203215Z"
    }
   },
   "outputs": [],
   "source": [
    "emotion_model = torch.compile(emotion_model, mode=\"reduce-overhead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ee3d7ef2f38aeba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.251074Z",
     "start_time": "2024-09-17T08:35:51.249386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): EmotionModel(\n",
      "    (_EmotionModel__weight_Q): Linear(in_features=7, out_features=7, bias=False)\n",
      "    (_EmotionModel__weight_K): Linear(in_features=7, out_features=7, bias=False)\n",
      "    (_EmotionModel__dropout): Dropout(p=0.5, inplace=False)\n",
      "    (_EmotionModel__weight_D): Linear(in_features=7, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(emotion_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3614cf1c44cfd954",
   "metadata": {},
   "source": "### Similarity Analyzer"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d46904b2cf2ec820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.301764Z",
     "start_time": "2024-09-17T08:35:51.300323Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold: float = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35923cab42231bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.347017Z",
     "start_time": "2024-09-17T08:35:51.345439Z"
    }
   },
   "outputs": [],
   "source": [
    "similarity_analyzer = SimilarityAnalyser(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7812a7b3f8d2bb9b",
   "metadata": {},
   "source": "## Combine All Modules"
  },
  {
   "cell_type": "markdown",
   "id": "6246f25cb03ad24b",
   "metadata": {},
   "source": "### Initialize"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1733c33e90049dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.390730Z",
     "start_time": "2024-09-17T08:35:51.389318Z"
    }
   },
   "outputs": [],
   "source": [
    "streamer = TextStreamer(\n",
    "    tokenizer, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "322fc7f3cf905a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.438269Z",
     "start_time": "2024-09-17T08:35:51.436961Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt: str = \"\"  # input(\"Enter your system prompt: \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e3e92093c478ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.489312Z",
     "start_time": "2024-09-17T08:35:51.485074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4817, 0.4091, 0.6996, 0.5359, 0.8497, 0.1423, 0.9519])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_bot_emotion_representation: Tensor = generate_dummy_representation(randint(0, 6))\n",
    "ideal_bot_emotion_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7fd1965488ecd1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.539821Z",
     "start_time": "2024-09-17T08:35:51.536379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3156, 0.2505, 0.9316, 0.6738, 0.3336, 0.1432, 0.4173])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_emotion_representation: Tensor = generate_dummy_representation(randint(0, 6))\n",
    "bot_emotion_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8da454aae4c41c25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.644020Z",
     "start_time": "2024-09-17T08:35:51.641764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{content: {dialog: , emotion: }, role: system}]\n"
     ]
    }
   ],
   "source": [
    "chat_buffer: list = ChatMessage(system_prompt=\"\")\n",
    "chat_buffer.show_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59f481da8f2af2ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:36:58.714427Z",
     "start_time": "2024-09-17T08:36:54.043495Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping cudagraphs due to mutated inputs (1 instances). Found from : \n",
      "   File \"/home/hermeschen/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py\", line 121, in torch_dynamo_resume_in_forward_at_120\n",
      "    embeddings += position_embeddings\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{content: {dialog: , emotion: }, role: system}, {content: {dialog: neutral, e â†ª\n",
      "\n",
      "â†ª motion: Hello, how are you?}, role: bot}, {content: {dialog: neutral, emotio â†ª\n",
      "\n",
      "â†ª n: Hello, how are you?}, role: user}]\n"
     ]
    }
   ],
   "source": [
    "input_text: str = \"Hello, how are you?\"  # input(\"Talk to bot...\").strip()\n",
    "input_text_emotion: list = sentiment_analyzer(\n",
    "    chat_buffer.get_message(-1)[\"content\"][\"dialog\"]\n",
    ")\n",
    "chat_buffer.append_message(get_top_emotion(input_text_emotion), input_text)\n",
    "chat_buffer.show_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4beb79e83f295be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:37:08.395399Z",
     "start_time": "2024-09-17T08:37:08.392559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3049, 0.1157, 0.1156, 0.1153, 0.1175, 0.1157, 0.1153])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_emotion_composition: Tensor = get_sentiment_composition(input_text_emotion)\n",
    "input_text_emotion_composition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d1ccda8b3518a",
   "metadata": {},
   "source": "### Update Current Bot's Emotion Representation"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24dc817b84a77cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:37:10.889066Z",
     "start_time": "2024-09-17T08:37:09.659433Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping cudagraphs due to skipping cudagraphs due to cpu device (primals_5). Found from : \n",
      "   File \"/home/hermeschen/Repo/chat-bot/src/models/libs/EmotionModel.py\", line 40, in forward\n",
      "    decomposed_representation: Tensor = representation.diag().to(\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4886, 0.2977, 0.2986, 0.2973, 0.2995, 0.2978, 0.2981],\n",
       "       device='cuda:0', grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_emotion_representation = emotion_model.forward(\n",
    "    input_text_emotion_composition, bot_emotion_representation\n",
    ")\n",
    "bot_emotion_representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab25273bbf80b65",
   "metadata": {},
   "source": "### Generate All Possible Responses In 7 Different Emotions"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff4d752b3e6be9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:37:12.805867Z",
     "start_time": "2024-09-17T08:37:12.783305Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'ChatMessage' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m candidates_buffer: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_candidates_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m candidates_buffer\n",
      "File \u001b[0;32m~/Repo/chat-bot/src/models/libs/FullModel.py:27\u001b[0m, in \u001b[0;36mcreate_candidates_buffer\u001b[0;34m(chat_buffer)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_candidates_buffer\u001b[39m(chat_buffer: \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m     16\u001b[0m     emotions: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manger\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurprise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     ]\n\u001b[1;32m     26\u001b[0m     candidates_buffer: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 27\u001b[0m         \u001b[43mchat_buffer\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43memotion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdialog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m emotion \u001b[38;5;129;01min\u001b[39;00m emotions\n\u001b[1;32m     35\u001b[0m     ]\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m candidates_buffer\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'ChatMessage' and 'list'"
     ]
    }
   ],
   "source": [
    "candidates_buffer: list = create_candidates_buffer(chat_buffer)\n",
    "candidates_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "177d0dc31017d0a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.837444455Z",
     "start_time": "2024-09-17T08:28:04.732861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   neutral   Hello, how are you?     neutral    Fine, thank you. \n",
      "   neutral   Hello, how are you?     anger   \n",
      "   neutral   Hello, how are you?     disgust   \n",
      "   neutral   Hello, how are you?     fear    Hi! I'm terribly nervous. \n",
      "   neutral   Hello, how are you?     happiness     Fine, thank you. \n",
      "   neutral   Hello, how are you?     sadness   \n",
      "   neutral   Hello, how are you?     surprise     Hi! I haven't seen you for ages! \n",
      "\n",
      "[[{'content': {'dialog': '', 'emotion': ''}, 'role': 'system'},\n",
      "  {'content': {'dialog': 'Hello, how are you?', 'emotion': 'neutral'},\n",
      "   'role': 'user'},\n",
      "  {'content': {'dialog': 'Fine, thank you.', 'emotion': 'neutral'},\n",
      "   'role': 'bot'}],\n",
      " [{'content': {'dialog': '', 'emotion': ''}, 'role': 'system'},\n",
      "  {'content': {'dialog': 'Hello, how are you?', 'emotion': 'neutral'},\n",
      "   'role': 'user'},\n",
      "  {'content': {'dialog': \"Hi! I'm terribly nervous.\", 'emotion': 'fear'},\n",
      "   'role': 'bot'}],\n",
      " [{'content': {'dialog': '', 'emotion': ''}, 'role': 'system'},\n",
      "  {'content': {'dialog': 'Hello, how are you?', 'emotion': 'neutral'},\n",
      "   'role': 'user'},\n",
      "  {'content': {'dialog': 'Fine, thank you.', 'emotion': 'happiness'},\n",
      "   'role': 'bot'}],\n",
      " [{'content': {'dialog': '', 'emotion': ''}, 'role': 'system'},\n",
      "  {'content': {'dialog': 'Hello, how are you?', 'emotion': 'neutral'},\n",
      "   'role': 'user'},\n",
      "  {'content': {'dialog': \"Hi! I haven't seen you for ages!\",\n",
      "               'emotion': 'surprise'},\n",
      "   'role': 'bot'}]]\n"
     ]
    }
   ],
   "source": [
    "generated_candidates: list = [\n",
    "    result[0]\n",
    "    for result in response_generator(candidates_buffer, streamer=streamer)\n",
    "    if result[0][-1][\"content\"][\"dialog\"] != \"\"\n",
    "]\n",
    "print()\n",
    "pprint(generated_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1623271d26e3b",
   "metadata": {},
   "source": "### Simulate Bot's Possible Emotion Representation"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adf9424c0ca6751f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.837494139Z",
     "start_time": "2024-09-17T08:28:07.278296Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping cudagraphs due to mutated inputs (1 instances). Found from : \n",
      "   File \"/home/hermeschen/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py\", line 121, in torch_dynamo_resume_in_forward_at_120\n",
      "    embeddings += position_embeddings\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neutral': tensor([0.1555, 0.1213, 0.1199, 0.1200, 0.2407, 0.1211, 0.1214]),\n",
       " 'fear': tensor([0.2466, 0.1217, 0.1203, 0.1285, 0.1364, 0.1227, 0.1238]),\n",
       " 'happiness': tensor([0.1555, 0.1213, 0.1199, 0.1200, 0.2407, 0.1211, 0.1214]),\n",
       " 'surprise': tensor([0.1562, 0.1223, 0.1210, 0.1232, 0.2309, 0.1218, 0.1245])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_response_emotion_composition: dict = (\n",
    "    get_possible_response_emotion_representation(\n",
    "        generated_candidates, emotion_predictor\n",
    "    )\n",
    ")\n",
    "possible_response_emotion_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8f0c947ddacbd18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.837552670Z",
     "start_time": "2024-09-17T08:28:21.881140Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping cudagraphs due to skipping cudagraphs due to cpu device (primals_5). Found from : \n",
      "   File \"/home/hermeschen/Repo/chat-bot/src/models/libs/EmotionModel.py\", line 40, in forward\n",
      "    decomposed_representation: Tensor = representation.diag().to(\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neutral': tensor([0.3390, 0.3033, 0.3030, 0.3020, 0.4225, 0.3033, 0.3041],\n",
       "        device='cuda:0', grad_fn=<CompiledFunctionBackward>),\n",
       " 'fear': tensor([0.4302, 0.3038, 0.3034, 0.3104, 0.3182, 0.3047, 0.3065],\n",
       "        device='cuda:0', grad_fn=<CompiledFunctionBackward>),\n",
       " 'happiness': tensor([0.3389, 0.3032, 0.3030, 0.3019, 0.4226, 0.3033, 0.3041],\n",
       "        device='cuda:0', grad_fn=<CompiledFunctionBackward>),\n",
       " 'surprise': tensor([0.3397, 0.3044, 0.3041, 0.3052, 0.4128, 0.3038, 0.3072],\n",
       "        device='cuda:0', grad_fn=<CompiledFunctionBackward>)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulated_emotion_representation: dict = {\n",
    "    k: emotion_model.forward(v, bot_emotion_representation)\n",
    "    for k, v in possible_response_emotion_composition.items()\n",
    "}\n",
    "simulated_emotion_representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792998ccbf3b5800",
   "metadata": {},
   "source": "### Compute Similarity Score"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c5181a6187a50f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.837619604Z",
     "start_time": "2024-09-17T08:28:22.184520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5040311217308044,\n",
       " 0.4850131571292877,\n",
       " 0.5039858818054199,\n",
       " 0.5041945576667786]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score: list = similarity_analyzer(\n",
    "    list(simulated_emotion_representation.values()), ideal_bot_emotion_representation\n",
    ").tolist()\n",
    "similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5dd17729ed157",
   "metadata": {},
   "source": "### Get Best Response Emotion"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b874daee7e4bec89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.837674514Z",
     "start_time": "2024-09-17T08:28:22.239458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions: list = [\n",
    "    \"neutral\",\n",
    "    \"anger\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"happiness\",\n",
    "    \"sadness\",\n",
    "    \"surprise\",\n",
    "]\n",
    "best_bot_response_emotion: str = emotions[\n",
    "    max(enumerate(similarity_score), key=itemgetter(1))[0]\n",
    "]\n",
    "best_bot_response_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7c336275ec5988c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.837725834Z",
     "start_time": "2024-09-17T08:28:22.289793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': {'emotion': '', 'dialog': ''}},\n",
       " {'role': 'user',\n",
       "  'content': {'emotion': 'neutral', 'dialog': 'Hello, how are you?'}},\n",
       " {'role': 'bot', 'content': {'emotion': 'fear', 'dialog': ''}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_buffer.append(\n",
    "    {\"role\": \"bot\", \"content\": {\"emotion\": best_bot_response_emotion, \"dialog\": \"\"}}\n",
    ")\n",
    "chat_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e440aaabe2be24",
   "metadata": {},
   "source": "### Response"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c14fd79e2ccadace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.837807495Z",
     "start_time": "2024-09-17T08:28:22.395718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   neutral   Hello, how are you?     fear    Hi! I'm scared! \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': {'emotion': '', 'dialog': ''}},\n",
       " {'role': 'user',\n",
       "  'content': {'emotion': 'neutral', 'dialog': 'Hello, how are you?'}},\n",
       " {'role': 'bot', 'content': {'emotion': 'fear', 'dialog': \"Hi! I'm scared!\"}}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_buffer = response_generator(chat_buffer, streamer=streamer)[0]\n",
    "chat_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36e10f33e0dd37f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.837902698Z",
     "start_time": "2024-09-17T08:28:22.857365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': {'emotion': '', 'dialog': ''}},\n",
       " {'role': 'user',\n",
       "  'content': {'emotion': 'neutral', 'dialog': 'Hello, how are you?'}},\n",
       " {'role': 'bot', 'content': {'emotion': 'fear', 'dialog': \"Hi! I'm scared!\"}}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(chat_buffer) > 11:\n",
    "    chat_buffer.pop(1)\n",
    "chat_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd66746b625fef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T08:35:51.837988976Z",
     "start_time": "2024-09-17T08:28:22.962860Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
