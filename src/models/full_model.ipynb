{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3ca6205fd0c59f",
   "metadata": {},
   "source": "# Emotion Chat Bot"
  },
  {
   "cell_type": "code",
   "id": "1a2aa4f1318f3251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:09.845614Z",
     "start_time": "2024-09-17T17:56:07.173705Z"
    }
   },
   "source": [
    "import os.path\n",
    "import uuid\n",
    "from random import randint\n",
    "\n",
    "import torch\n",
    "from libs import (\n",
    "\tEmotionModel,\n",
    "\tEmotionPresentationSimilarityAnalyser,\n",
    "\tResponseGeneratorPipeline,\n",
    "\tgenerate_dummy_representation,\n",
    "\tget_sentiment_composition,\n",
    ")\n",
    "from libs.FullModel import create_candidates_buffer, get_top_emotion, write_log_file\n",
    "from torch import Tensor\n",
    "from transformers import (\n",
    "\tAutoModelForSequenceClassification,\n",
    "\tAutoTokenizer,\n",
    "\tBitsAndBytesConfig,\n",
    "\tTextStreamer,\n",
    "\tpipeline, GenerationConfig,\n",
    ")\n",
    "from unsloth import FastLanguageModel"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "7df2ec80ac934263",
   "metadata": {},
   "source": "## Load Each Module"
  },
  {
   "cell_type": "markdown",
   "id": "bbdd58114a803167",
   "metadata": {},
   "source": "### Response Generator"
  },
  {
   "cell_type": "code",
   "id": "4c80a1ee1d967a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:17.448870Z",
     "start_time": "2024-09-17T17:56:09.853362Z"
    }
   },
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "\tmodel_name=\"hermeschen1116/response_generator_for_emotion_chat_bot\",\n",
    "\tattn_implementation=\"flash_attention_2\",\n",
    "\tpretraining_tp=1,\n",
    "\tload_in_4bit=True,\n",
    "\tdevice_map=\"auto\",\n",
    "\tlow_cpu_mem_usage=True,\n",
    "\ttrust_remote_code=True,\n",
    ")\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.clean_up_tokenization_spaces = True"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth 2024.9: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3060. Max memory: 11.754 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "7d8c87bb53c02a3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:17.502344Z",
     "start_time": "2024-09-17T17:56:17.500821Z"
    }
   },
   "source": [
    "response_generator = ResponseGeneratorPipeline(\n",
    "\tmodel,\n",
    "\ttokenizer,\n",
    "\tframework=\"pt\",\n",
    "\ttask=\"conversation-generation\",\n",
    "\tnum_workers=16,\n",
    "\ttorch_dtype=\"auto\",\n",
    "\tadd_special_tokens=True,\n",
    "\ttruncation=False,\n",
    "\tpadding=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "10795eec37f51bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:17.547035Z",
     "start_time": "2024-09-17T17:56:17.545175Z"
    }
   },
   "source": [
    "FastLanguageModel.for_inference(response_generator.model)\n",
    "response_generator.model = torch.compile(response_generator.model)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "5e3a0f6986c4c83f",
   "metadata": {},
   "source": "### Sentiment Analyzer"
  },
  {
   "cell_type": "code",
   "id": "6e4e8f191cc8b3ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:18.029220Z",
     "start_time": "2024-09-17T17:56:17.588579Z"
    }
   },
   "source": [
    "sentiment_analysis_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\t\"Shotaro30678/sentiment_analysis_for_emotion_chat_bot\",\n",
    "\tquantization_config=BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16),\n",
    "\tdevice_map=\"auto\",\n",
    "\tlow_cpu_mem_usage=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "701fbd337943d5ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:18.262691Z",
     "start_time": "2024-09-17T17:56:18.035565Z"
    }
   },
   "source": [
    "sentiment_analysis_tokenizer = AutoTokenizer.from_pretrained(\n",
    "\t\"Shotaro30678/sentiment_analysis_for_emotion_chat_bot\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "bd6d594d260a8043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:18.272471Z",
     "start_time": "2024-09-17T17:56:18.270935Z"
    }
   },
   "source": [
    "sentiment_analyzer = pipeline(\n",
    "\t\"sentiment-analysis\",\n",
    "\tmodel=sentiment_analysis_model,\n",
    "\ttokenizer=sentiment_analysis_tokenizer,\n",
    "\ttop_k=7,\n",
    "\ttorch_dtype=torch.float32,\n",
    "\tdevice_map=\"auto\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9681c0078abce320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:18.315313Z",
     "start_time": "2024-09-17T17:56:18.313474Z"
    }
   },
   "source": [
    "sentiment_analyzer.model = torch.compile(sentiment_analyzer.model)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "5d0c90aa00097046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:18.361290Z",
     "start_time": "2024-09-17T17:56:18.359266Z"
    }
   },
   "source": [
    "print(sentiment_analyzer.model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "7b7f77a5a4fbf0e2",
   "metadata": {},
   "source": "### Emotion Predictor"
  },
  {
   "cell_type": "code",
   "id": "7c675bfb19becf6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:18.841390Z",
     "start_time": "2024-09-17T17:56:18.407216Z"
    }
   },
   "source": [
    "emotion_predictor_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\t\"Shotaro30678/emotion_predictor_for_emotion_chat_bot\",\n",
    "\tquantization_config=BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16),\n",
    "\tdevice_map=\"auto\",\n",
    "\tlow_cpu_mem_usage=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "b1d5b572b25d2871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.066102Z",
     "start_time": "2024-09-17T17:56:18.850090Z"
    }
   },
   "source": [
    "emotion_predictor_tokenizer = AutoTokenizer.from_pretrained(\n",
    "\t\"Shotaro30678/emotion_predictor_for_emotion_chat_bot\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "d3d609d13ac1305c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.079099Z",
     "start_time": "2024-09-17T17:56:19.077500Z"
    }
   },
   "source": [
    "emotion_predictor = pipeline(\n",
    "\t\"sentiment-analysis\",\n",
    "\tmodel=emotion_predictor_model,\n",
    "\ttokenizer=emotion_predictor_tokenizer,\n",
    "\ttop_k=7,\n",
    "\ttorch_dtype=torch.float32,\n",
    "\tdevice_map=\"auto\",\n",
    "\ttrust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "e83e581f580f9487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.123878Z",
     "start_time": "2024-09-17T17:56:19.121821Z"
    }
   },
   "source": [
    "emotion_predictor.model = torch.compile(emotion_predictor.model)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "f08b9c106afb713e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.173415Z",
     "start_time": "2024-09-17T17:56:19.171485Z"
    }
   },
   "source": [
    "print(emotion_predictor.model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "dceb3e74297ea1a9",
   "metadata": {},
   "source": "### Emotion Model"
  },
  {
   "cell_type": "code",
   "id": "8f257727afd216a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.606315Z",
     "start_time": "2024-09-17T17:56:19.219561Z"
    }
   },
   "source": [
    "emotion_model = EmotionModel.from_pretrained(\"hermeschen1116/emotion_model_for_emotion_chat_bot\")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "5420819fd9f588af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.620563Z",
     "start_time": "2024-09-17T17:56:19.618952Z"
    }
   },
   "source": [
    "emotion_model = torch.compile(emotion_model, mode=\"reduce-overhead\")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "4ee3d7ef2f38aeba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.666225Z",
     "start_time": "2024-09-17T17:56:19.664532Z"
    }
   },
   "source": [
    "print(emotion_model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): EmotionModel(\n",
      "    (_EmotionModel__weight_Q): Linear(in_features=7, out_features=7, bias=False)\n",
      "    (_EmotionModel__weight_K): Linear(in_features=7, out_features=7, bias=False)\n",
      "    (_EmotionModel__dropout): Dropout(p=0.5, inplace=False)\n",
      "    (_EmotionModel__weight_D): Linear(in_features=7, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "3614cf1c44cfd954",
   "metadata": {},
   "source": "### Similarity Analyzer"
  },
  {
   "cell_type": "code",
   "id": "d46904b2cf2ec820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.716636Z",
     "start_time": "2024-09-17T17:56:19.715200Z"
    }
   },
   "source": [
    "threshold: float = 0.7"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "35923cab42231bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.766468Z",
     "start_time": "2024-09-17T17:56:19.764980Z"
    }
   },
   "source": [
    "similarity_analyzer = EmotionPresentationSimilarityAnalyser(None, threshold=threshold)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "7812a7b3f8d2bb9b",
   "metadata": {},
   "source": "## Combine All Modules"
  },
  {
   "cell_type": "code",
   "id": "e6d48c0c4bcd7c0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.812494Z",
     "start_time": "2024-09-17T17:56:19.811044Z"
    }
   },
   "source": [
    "emotions: list = [\n",
    "\t\"neutral\",\n",
    "\t\"anger\",\n",
    "\t\"disgust\",\n",
    "\t\"fear\",\n",
    "\t\"happiness\",\n",
    "\t\"sadness\",\n",
    "\t\"surprise\",\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "6246f25cb03ad24b",
   "metadata": {},
   "source": "### Initialize"
  },
  {
   "cell_type": "code",
   "id": "a5bba438f3869366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.858316Z",
     "start_time": "2024-09-17T17:56:19.856911Z"
    }
   },
   "source": [
    "chat_buffer_size: int = 10"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "bbd8163729f358f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.902767Z",
     "start_time": "2024-09-17T17:56:19.901205Z"
    }
   },
   "source": [
    "logfile_uuid: uuid.UUID = uuid.uuid4()\n",
    "if not os.path.isdir(\"./logs\"):\n",
    "\tos.mkdir(\"./logs\")"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.946508Z",
     "start_time": "2024-09-17T17:56:19.944942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generation_config = GenerationConfig(\n",
    "\tmax_new_tokens=20,\n",
    "\tmin_new_tokens=5,\n",
    "\trepetition_penalty=1.5,\n",
    "\tpad_token_id=tokenizer.pad_token_id,\n",
    "\teos_token_id=tokenizer.eos_token_id,\n",
    "\tuse_cache=True\n",
    ")"
   ],
   "id": "bf5aaf39bbdaf0cd",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "1733c33e90049dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:19.990673Z",
     "start_time": "2024-09-17T17:56:19.989047Z"
    }
   },
   "source": [
    "streamer = TextStreamer(tokenizer, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "8e3e92093c478ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:20.039876Z",
     "start_time": "2024-09-17T17:56:20.036622Z"
    }
   },
   "source": [
    "bot_ideal_emotion_representation: Tensor = generate_dummy_representation(randint(0, 6))\n",
    "similarity_analyzer.ideal_emotion_representation = bot_ideal_emotion_representation\n",
    "dict(zip(emotions, bot_ideal_emotion_representation.tolist()))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0.05590778589248657,\n",
       " 'anger': 0.9465583562850952,\n",
       " 'disgust': 0.3423585295677185,\n",
       " 'fear': 0.3062811493873596,\n",
       " 'happiness': 0.30860453844070435,\n",
       " 'sadness': 0.7816214561462402,\n",
       " 'surprise': 0.3608524203300476}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "a7fd1965488ecd1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:20.147137Z",
     "start_time": "2024-09-17T17:56:20.144307Z"
    }
   },
   "source": [
    "bot_emotion_id: int = randint(0, 6)\n",
    "bot_emotion_representation: Tensor = generate_dummy_representation(bot_emotion_id)\n",
    "bot_emotion_representation"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1686, 0.7951, 0.5369, 0.9070, 0.4718, 0.8152, 0.1327])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "322fc7f3cf905a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:22.578657Z",
     "start_time": "2024-09-17T17:56:20.245425Z"
    }
   },
   "source": [
    "system_prompt: str = input(\"Enter your system prompt: \").strip()\n",
    "bot_response: dict = {\"emotion\": emotions[bot_emotion_id], \"dialog\": \"(Talk to me...)\"}"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "8da454aae4c41c25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:22.593743Z",
     "start_time": "2024-09-17T17:56:22.592251Z"
    }
   },
   "source": [
    "chat_buffer: list = [{\"role\": \"system\", \"content\": {\"emotion\": \"\", \"dialog\": system_prompt}}]"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "38d2e521a8d16664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:56:22.640646Z",
     "start_time": "2024-09-17T17:56:22.638233Z"
    }
   },
   "source": [
    "chat_buffer"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': {'emotion': '', 'dialog': ''}}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "b5f10bbc9baa3309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T17:57:14.311873Z",
     "start_time": "2024-09-17T17:56:22.742864Z"
    }
   },
   "source": [
    "while True:\n",
    "\tuser_response: str = input(f\"Bot({bot_response[\"emotion\"]}): {bot_response[\"dialog\"]}\").strip()\n",
    "\tif user_response == \"quit\":\n",
    "\t\tbreak\n",
    "\n",
    "\tuser_emotion: list = sentiment_analyzer(user_response)[0]\n",
    "\tchat_buffer.append(\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": {\n",
    "\t\t\t\t\"emotion\": get_top_emotion(user_emotion),\n",
    "\t\t\t\t\"dialog\": user_response,\n",
    "\t\t\t},\n",
    "\t\t}\n",
    "\t)\n",
    "\n",
    "\tuser_emotion_composition: Tensor = get_sentiment_composition(user_emotion)\n",
    "\n",
    "\tbot_emotion_representation = emotion_model.forward(user_emotion_composition, bot_emotion_representation)\n",
    "\n",
    "\tbot_chat_simulations: list = []\n",
    "\twhile True:\n",
    "\t\tbot_chat_simulations = create_candidates_buffer(chat_buffer)\n",
    "\t\tbot_chat_simulations = [chat[0] for chat in response_generator(bot_chat_simulations, generation_config=generation_config, streamer=streamer)]\n",
    "\t\tprint()\n",
    "\t\twrite_log_file(logfile_uuid, bot_chat_simulations)\n",
    "\t\tbot_chat_simulations = list(filter(lambda chat: chat[-1][\"content\"][\"dialog\"] != \"\", bot_chat_simulations))\n",
    "\t\tbot_chat_simulations = list(filter(lambda chat: chat[-1][\"content\"][\"dialog\"].endswith((\".\", \"!\", \"?\")), bot_chat_simulations))\n",
    "\t\tif len(bot_chat_simulations) != 0:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tbot_response_simulations: list = [chat[-1][\"content\"] for chat in bot_chat_simulations]\n",
    "\n",
    "\tuser_future_emotion_composition_simulations: dict = {\n",
    "\t\tresponse[\"emotion\"]: get_sentiment_composition(emotion_predictor(response[\"dialog\"])[0])\n",
    "\t\tfor response in bot_response_simulations\n",
    "\t}\n",
    "\n",
    "\tbot_future_emotion_representations: dict = {\n",
    "\t\tk: emotion_model.forward(v, bot_emotion_representation)\n",
    "\t\tfor k, v in user_future_emotion_composition_simulations.items()\n",
    "\t}\n",
    "\n",
    "\temotion_representation_similarity_scores: list = similarity_analyzer(\n",
    "\t\ttorch.stack(list(bot_future_emotion_representations.values())),\n",
    "\t)\n",
    "\n",
    "\tcandidate_emotion_index: int = torch.argmax(emotion_representation_similarity_scores).item()\n",
    "\tbot_best_response_emotion: str = emotions[candidate_emotion_index]\n",
    "\n",
    "\tif len(chat_buffer) == chat_buffer_size + 1:\n",
    "\t\tchat_buffer.pop(1)\n",
    "\tchat_buffer.append({\"role\": \"bot\", \"content\": {\"emotion\": bot_best_response_emotion, \"dialog\": \"\"}})\n",
    "\n",
    "\tchat_buffer = response_generator(chat_buffer, generation_config=generation_config, streamer=streamer)[0]\n",
    "\tprint()\n",
    "\tif chat_buffer[-1][\"content\"][\"dialog\"] == \"\":\n",
    "\t\tchat_buffer[-1][\"content\"][\"dialog\"] = bot_response_simulations[candidate_emotion_index][\"dialog\"]\n",
    "\tbot_response = chat_buffer[-1][\"content\"]\n",
    "\twrite_log_file(logfile_uuid, chat_buffer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   neutral   Why you fear?     neutral    because I'm afraid of the darkness. \n",
      "   neutral   Why you fear?     anger    because he is a bad man. He will hurt me! \n",
      "   neutral   Why you fear?     disgust    because he is so stupid. He makes me sick! \n",
      "   neutral   Why you fear?     fear    because I'm afraid of the darkness. \n",
      "   neutral   Why you fear?     happiness     I'm afraid of the darkness. \n",
      "   neutral   Why you fear?     sadness    because I failed the exam. \n",
      "   neutral   Why you fear?     surprise     Fear! I'm not afraid. \n",
      "\n",
      "   neutral   Why you fear?     anger    because he is a bad man. He will hurt me! \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m----> 2\u001B[0m \tuser_response: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mBot(\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mbot_response\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43memotion\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m): \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mbot_response\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdialog\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[1;32m      3\u001B[0m \t\u001B[38;5;28;01mif\u001B[39;00m user_response \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquit\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m      4\u001B[0m \t\t\u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[0;34m(self, prompt)\u001B[0m\n\u001B[1;32m   1280\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[0;32m-> 1282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1287\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repo/chat-bot/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[0;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[1;32m   1322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[1;32m   1323\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[1;32m   1324\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1325\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1326\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd66746b625fef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
