{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3ca6205fd0c59f",
   "metadata": {},
   "source": "# Emotion Chat Bot"
  },
  {
   "cell_type": "code",
   "id": "1a2aa4f1318f3251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T13:05:34.942911Z",
     "start_time": "2024-09-17T13:05:33.144475Z"
    }
   },
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "from libs import (\n",
    "    EmotionModel,\n",
    "    ResponseGeneratorPipeline,\n",
    "    SimilarityAnalyser,\n",
    "    generate_dummy_representation,\n",
    "    get_sentiment_composition,\n",
    ")\n",
    "from libs.FullModel import (\n",
    "    create_candidates_buffer,\n",
    "    get_top_emotion,\n",
    ")\n",
    "from sympy.core.random import randint\n",
    "from torch import Tensor\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TextStreamer,\n",
    "    pipeline,\n",
    ")\n",
    "from unsloth import FastLanguageModel"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'candidates' from 'transformers.utils.import_utils' (/home/hermeschen/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 24\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Tensor\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     18\u001B[0m     AutoModelForSequenceClassification,\n\u001B[1;32m     19\u001B[0m     AutoTokenizer,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m     pipeline,\n\u001B[1;32m     23\u001B[0m )\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimport_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m candidates\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munsloth\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FastLanguageModel\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'candidates' from 'transformers.utils.import_utils' (/home/hermeschen/Repo/chat-bot/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "7df2ec80ac934263",
   "metadata": {},
   "source": "## Load Each Module"
  },
  {
   "cell_type": "markdown",
   "id": "bbdd58114a803167",
   "metadata": {},
   "source": "### Response Generator"
  },
  {
   "cell_type": "code",
   "id": "4c80a1ee1d967a87",
   "metadata": {},
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"hermeschen1116/response_generator_for_emotion_chat_bot\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    pretraining_tp=1,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7d8c87bb53c02a3b",
   "metadata": {},
   "source": [
    "response_generator = ResponseGeneratorPipeline(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    framework=\"pt\",\n",
    "    task=\"conversation-generation\",\n",
    "    num_workers=16,\n",
    "    torch_dtype=\"auto\",\n",
    "    add_special_tokens=True,\n",
    "    truncation=False,\n",
    "    padding=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10795eec37f51bae",
   "metadata": {},
   "source": [
    "FastLanguageModel.for_inference(response_generator.model)\n",
    "response_generator.model = torch.compile(\n",
    "    response_generator.model, mode=\"reduce-overhead\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5e3a0f6986c4c83f",
   "metadata": {},
   "source": "### Sentiment Analyzer"
  },
  {
   "cell_type": "code",
   "id": "6e4e8f191cc8b3ef",
   "metadata": {},
   "source": [
    "sentiment_analysis_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"Shotaro30678/sentiment_analysis_for_emotion_chat_bot\",\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16\n",
    "    ),\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "701fbd337943d5ea",
   "metadata": {},
   "source": [
    "sentiment_analysis_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Shotaro30678/sentiment_analysis_for_emotion_chat_bot\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bd6d594d260a8043",
   "metadata": {},
   "source": [
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=sentiment_analysis_model,\n",
    "    tokenizer=sentiment_analysis_tokenizer,\n",
    "    top_k=7,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9681c0078abce320",
   "metadata": {},
   "source": [
    "sentiment_analyzer.model = torch.compile(\n",
    "    sentiment_analyzer.model, mode=\"reduce-overhead\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d0c90aa00097046",
   "metadata": {},
   "source": [
    "print(sentiment_analyzer.model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7b7f77a5a4fbf0e2",
   "metadata": {},
   "source": "### Emotion Predictor"
  },
  {
   "cell_type": "code",
   "id": "7c675bfb19becf6d",
   "metadata": {},
   "source": [
    "emotion_predictor_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"Shotaro30678/emotion_predictor_for_emotion_chat_bot\",\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16\n",
    "    ),\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1d5b572b25d2871",
   "metadata": {},
   "source": [
    "emotion_predictor_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Shotaro30678/emotion_predictor_for_emotion_chat_bot\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3d609d13ac1305c",
   "metadata": {},
   "source": [
    "emotion_predictor = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=emotion_predictor_model,\n",
    "    tokenizer=emotion_predictor_tokenizer,\n",
    "    top_k=7,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e83e581f580f9487",
   "metadata": {},
   "source": [
    "emotion_predictor.model = torch.compile(emotion_predictor.model, mode=\"reduce-overhead\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f08b9c106afb713e",
   "metadata": {},
   "source": [
    "print(emotion_predictor.model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dceb3e74297ea1a9",
   "metadata": {},
   "source": "### Emotion Model"
  },
  {
   "cell_type": "code",
   "id": "8f257727afd216a9",
   "metadata": {},
   "source": [
    "emotion_model = EmotionModel.from_pretrained(\n",
    "    \"hermeschen1116/emotion_model_for_emotion_chat_bot\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5420819fd9f588af",
   "metadata": {},
   "source": [
    "emotion_model = torch.compile(emotion_model, mode=\"reduce-overhead\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ee3d7ef2f38aeba",
   "metadata": {},
   "source": [
    "print(emotion_model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3614cf1c44cfd954",
   "metadata": {},
   "source": "### Similarity Analyzer"
  },
  {
   "cell_type": "code",
   "id": "d46904b2cf2ec820",
   "metadata": {},
   "source": [
    "threshold: float = 0.5"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35923cab42231bf",
   "metadata": {},
   "source": [
    "similarity_analyzer = SimilarityAnalyser(threshold)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7812a7b3f8d2bb9b",
   "metadata": {},
   "source": "## Combine All Modules"
  },
  {
   "cell_type": "markdown",
   "id": "6246f25cb03ad24b",
   "metadata": {},
   "source": "### Initialize"
  },
  {
   "cell_type": "code",
   "id": "a5bba438f3869366",
   "metadata": {},
   "source": [
    "chat_buffer_size: int = 10"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1733c33e90049dff",
   "metadata": {},
   "source": [
    "streamer = TextStreamer(\n",
    "    tokenizer, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e3e92093c478ec",
   "metadata": {},
   "source": [
    "ideal_bot_emotion_representation: Tensor = generate_dummy_representation(randint(0, 6))\n",
    "ideal_bot_emotion_representation"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a7fd1965488ecd1a",
   "metadata": {},
   "source": [
    "bot_emotion_representation: Tensor = generate_dummy_representation(randint(0, 6))\n",
    "bot_emotion_representation"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "322fc7f3cf905a65",
   "metadata": {},
   "source": [
    "system_prompt: str = input(\"Enter your system prompt: \").strip()\n",
    "bot_message: str = \"Talk to me...\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8da454aae4c41c25",
   "metadata": {},
   "source": [
    "chat_buffer: list = [\n",
    "    {\"role\": \"system\", \"content\": {\"emotion\": \"\", \"dialog\": system_prompt}}\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "38d2e521a8d16664",
   "metadata": {},
   "source": [
    "chat_buffer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b5f10bbc9baa3309",
   "metadata": {},
   "source": [
    "while True:\n",
    "    user_response: str = input(f\"Bot: {bot_message}\").strip()\n",
    "    if user_response == \"quit\":\n",
    "        break\n",
    "\n",
    "    user_emotion: list = sentiment_analyzer(user_response)\n",
    "    chat_buffer.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": {\n",
    "                \"emotion\": get_top_emotion(user_emotion),\n",
    "                \"dialog\": user_response,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "    user_emotion_composition: Tensor = get_sentiment_composition(user_emotion)\n",
    "\n",
    "    bot_emotion_representation = emotion_model.forward(\n",
    "        user_emotion_composition, bot_emotion_representation\n",
    "    )\n",
    "\n",
    "    bot_chat_simulations: list = create_candidates_buffer(chat_buffer)\n",
    "    bot_chat_simulations = [\n",
    "        chat[0] for chat in response_generator(bot_chat_simulations, streamer=streamer)\n",
    "    ]\n",
    "    print()\n",
    "    # bot_chat_simulations = [chat[0] for chat in response_generator(bot_chat_simulations)]\n",
    "    bot_chat_simulations = list(\n",
    "        filter(lambda chat: chat[-1][\"content\"][\"dialog\"] != \"\", bot_chat_simulations)\n",
    "    )\n",
    "\n",
    "    bot_response_simulations: list = [\n",
    "        chat[-1][\"content\"] for chat in bot_chat_simulations\n",
    "    ]\n",
    "\n",
    "    user_future_emotion_composition_simulations: dict = {\n",
    "        response[\"emotion\"]: get_sentiment_composition(\n",
    "            emotion_predictor(response[\"dialog\"])\n",
    "        )\n",
    "        for response in bot_response_simulations\n",
    "    }\n",
    "\n",
    "    bot_future_emotion_representations: dict = {\n",
    "        k: emotion_model.forward(v, bot_emotion_representation)\n",
    "        for k, v in user_future_emotion_composition_simulations.items()\n",
    "    }\n",
    "\n",
    "    emotion_representation_similarity_scores: list = similarity_analyzer(\n",
    "        list(bot_future_emotion_representations.values()),\n",
    "        ideal_bot_emotion_representation,\n",
    "    ).tolist()\n",
    "\n",
    "    emotions: list = [\n",
    "        \"neutral\",\n",
    "        \"anger\",\n",
    "        \"disgust\",\n",
    "        \"fear\",\n",
    "        \"happiness\",\n",
    "        \"sadness\",\n",
    "        \"surprise\",\n",
    "    ]\n",
    "    bot_best_response_emotion: str = emotions[\n",
    "        max(enumerate(emotion_representation_similarity_scores), key=itemgetter(1))[0]\n",
    "    ]\n",
    "\n",
    "    if len(chat_buffer) == chat_buffer_size + 1:\n",
    "        chat_buffer.pop(1)\n",
    "    chat_buffer.append(\n",
    "        {\"role\": \"bot\", \"content\": {\"emotion\": bot_best_response_emotion, \"dialog\": \"\"}}\n",
    "    )\n",
    "\n",
    "    chat_buffer = response_generator(chat_buffer, streamer=streamer)[0]\n",
    "    print()\n",
    "    if chat_buffer[-1][\"content\"][\"dialog\"] == \"\":\n",
    "        chat_buffer[-1][\"content\"][\"dialog\"] = dict(\n",
    "            filter(lambda x: x.key() == bot_best_response_emotion, bot_chat_simulations)\n",
    "        ).value()\n",
    "    bot_message = chat_buffer[-1][\"content\"][\"dialog\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5dd66746b625fef4",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
