{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T11:51:48.346336Z",
     "start_time": "2024-04-17T11:51:48.343353Z"
    }
   },
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from EmotionModel import EmotionModel"
   ],
   "outputs": [],
   "execution_count": 281
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T11:51:48.355094Z",
     "start_time": "2024-04-17T11:51:48.351118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dtype = torch.float32\n",
    "device: str = \"mps\""
   ],
   "id": "7843c1eef483ad9e",
   "outputs": [],
   "execution_count": 282
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T11:51:48.367620Z",
     "start_time": "2024-04-17T11:51:48.364666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dummy_representation_generator() -> torch.tensor:\n",
    "    return torch.clamp(torch.rand(7, dtype=dtype, device=device), -1, 1)"
   ],
   "id": "950180f439d6e8e0",
   "outputs": [],
   "execution_count": 283
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T11:51:48.407369Z",
     "start_time": "2024-04-17T11:51:48.395082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# key\n",
    "representation: torch.tensor = torch.softmax(dummy_representation_generator(), dim=0, dtype=dtype)\n",
    "representation"
   ],
   "id": "27c91b4476dd8d9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0782, 0.1151, 0.0839, 0.2028, 0.1703, 0.1798, 0.1699],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 284
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T11:51:48.420965Z",
     "start_time": "2024-04-17T11:51:48.408982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "representation = torch.diag(representation)\n",
    "representation"
   ],
   "id": "484cc950af0ea878",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0782, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1151, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0839, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.2028, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1703, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1798, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1699]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 285
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T11:51:48.435601Z",
     "start_time": "2024-04-17T11:51:48.423395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# query\n",
    "input_emotion: torch.tensor = dummy_representation_generator()\n",
    "input_emotion"
   ],
   "id": "2eb00396eaba40c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5260, 0.0833, 0.4468, 0.5620, 0.0570, 0.1224, 0.3910],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 286
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T11:51:48.442311Z",
     "start_time": "2024-04-17T11:51:48.439042Z"
    }
   },
   "cell_type": "code",
   "source": "model = EmotionModel(\"dot_product\")",
   "id": "81d9ebdf41a69bda",
   "outputs": [],
   "execution_count": 287
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T11:51:48.448836Z",
     "start_time": "2024-04-17T11:51:48.443484Z"
    }
   },
   "cell_type": "code",
   "source": "new_representation = model.forward(representation, input_emotion)",
   "id": "d62a4cd622bbd844",
   "outputs": [],
   "execution_count": 288
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T11:51:48.470493Z",
     "start_time": "2024-04-17T11:51:48.450704Z"
    }
   },
   "cell_type": "code",
   "source": "new_representation",
   "id": "9efd3c28edbba14a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1518, -0.2973,  0.0901,  0.1285,  0.1176,  0.2459,  0.1481],\n",
       "       grad_fn=<ClampBackward1>)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 289
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T11:51:48.478263Z",
     "start_time": "2024-04-17T11:51:48.473328Z"
    }
   },
   "cell_type": "code",
   "source": "torch.argmax(new_representation)",
   "id": "92bf3497126d9e12",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 290
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T11:51:48.482700Z",
     "start_time": "2024-04-17T11:51:48.479530Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1b36231ef484ea79",
   "outputs": [],
   "execution_count": 290
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
