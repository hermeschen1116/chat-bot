{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T10:29:26.739183Z",
     "start_time": "2023-11-17T10:28:49.861600Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -Uq peft transformers datasets huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T10:29:52.653519Z",
     "start_time": "2023-11-17T10:29:31.566789Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/hermeschen/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\", add_to_git_credential=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T10:29:55.752319Z",
     "start_time": "2023-11-17T10:29:52.632625Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:39.050117Z",
     "start_time": "2023-10-25T17:52:39.044092Z"
    }
   },
   "outputs": [],
   "source": [
    "device: str = \"cpu\"\n",
    "model_name: str = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:39.050381Z",
     "start_time": "2023-10-25T17:52:39.047359Z"
    }
   },
   "outputs": [],
   "source": [
    "model_config = PromptTuningConfig(\n",
    "\ttask_type=TaskType.CAUSAL_LM,\n",
    "\tprompt_tuning_init=PromptTuningInit.TEXT,\n",
    "\tnum_virtual_tokens=8,\n",
    "\tprompt_tuning_init_text=\"Classify the emotion in the following sentence:\",\n",
    "\ttokenizer_name_or_path=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:39.055303Z",
     "start_time": "2023-10-25T17:52:39.051093Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name: str = \"daily_dialog\"\n",
    "max_sequence_length = 4096\n",
    "learning_rate = 3e-2\n",
    "num_epochs = 50\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:40.875707Z",
     "start_time": "2023-10-25T17:52:39.052950Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "emotions: list = list(dataset[\"train\"].features[\"emotion\"].feature.names)\n",
    "emotions[0] = \"neutral\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:40.881163Z",
     "start_time": "2023-10-25T17:52:40.876632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "\tlambda samples: {\n",
    "\t\t\"previous_dialog\": [sample[:-1] for sample in samples[\"dialog\"]]\n",
    "\t},\n",
    "\tbatched=True,\n",
    "\tnum_proc=8\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:40.930654Z",
     "start_time": "2023-10-25T17:52:40.879606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "\tlambda samples: {\n",
    "\t\t\"correspond_dialog\": [sample[1:] for sample in samples[\"dialog\"]]\n",
    "\t},\n",
    "\tbatched=True,\n",
    "\tnum_proc=8\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:40.978368Z",
     "start_time": "2023-10-25T17:52:40.931609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "\tlambda samples: {\n",
    "\t\t\"current_emotion\": [[emotions[label] for label in sample][:-1] for sample in samples[\"emotion\"]]\n",
    "\t},\n",
    "\tbatched=True,\n",
    "\tnum_proc=8\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:41.025543Z",
     "start_time": "2023-10-25T17:52:40.980260Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "\tlambda samples: {\n",
    "\t\t\"correspond_emotion\": [[emotions[label] for label in sample][1:] for sample in samples[\"emotion\"]]\n",
    "\t},\n",
    "\tbatched=True,\n",
    "\tnum_proc=8\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:41.058326Z",
     "start_time": "2023-10-25T17:52:41.026756Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'dialog': ['Say , Jim , how about going for a few beers after dinner ? ',\n  ' You know that is tempting but is really not good for our fitness . ',\n  ' What do you mean ? It will help us to relax . ',\n  \" Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ? \",\n  \" I guess you are right.But what shall we do ? I don't feel like sitting at home . \",\n  ' I suggest a walk over to the gym where we can play singsong and meet some of our friends . ',\n  \" That's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \",\n  ' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . ',\n  \" Good.Let ' s go now . \",\n  ' All right . '],\n 'act': [3, 4, 2, 2, 2, 3, 4, 1, 3, 4],\n 'emotion': [0, 0, 0, 0, 0, 0, 4, 4, 4, 4],\n 'previous_dialog': ['Say , Jim , how about going for a few beers after dinner ? ',\n  ' You know that is tempting but is really not good for our fitness . ',\n  ' What do you mean ? It will help us to relax . ',\n  \" Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ? \",\n  \" I guess you are right.But what shall we do ? I don't feel like sitting at home . \",\n  ' I suggest a walk over to the gym where we can play singsong and meet some of our friends . ',\n  \" That's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \",\n  ' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . ',\n  \" Good.Let ' s go now . \"],\n 'correspond_dialog': [' You know that is tempting but is really not good for our fitness . ',\n  ' What do you mean ? It will help us to relax . ',\n  \" Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ? \",\n  \" I guess you are right.But what shall we do ? I don't feel like sitting at home . \",\n  ' I suggest a walk over to the gym where we can play singsong and meet some of our friends . ',\n  \" That's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \",\n  ' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . ',\n  \" Good.Let ' s go now . \",\n  ' All right . '],\n 'current_emotion': ['neutral',\n  'neutral',\n  'neutral',\n  'neutral',\n  'neutral',\n  'neutral',\n  'happiness',\n  'happiness',\n  'happiness'],\n 'correspond_emotion': ['neutral',\n  'neutral',\n  'neutral',\n  'neutral',\n  'neutral',\n  'happiness',\n  'happiness',\n  'happiness',\n  'happiness']}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:41.064011Z",
     "start_time": "2023-10-25T17:52:41.060830Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:41.310004Z",
     "start_time": "2023-10-25T17:52:41.063464Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id if (tokenizer.pad_token_id is None) else tokenizer.pad_token_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:41.315199Z",
     "start_time": "2023-10-25T17:52:41.312516Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_label_max_length: int = max([len(tokenizer(label)[\"input_ids\"]) for label in emotions])\n",
    "emotion_label_max_length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:41.320149Z",
     "start_time": "2023-10-25T17:52:41.315397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def preprocess(samples):\n",
    "\tmodel_inputs = tokenizer([\n",
    "\t\tf\"previous_dialog: {sample[0][i]}, correspond_emotion: {sample[1][i]} => correspond_dialog: \"\n",
    "\t\tfor sample in zip(samples[\"previous_dialog\"], samples[\"correspond_emotion\"]) for i\n",
    "\t\tin range(len(sample[0]))])\n",
    "\tlabels = tokenizer(\n",
    "\t\t[str(correspond_dialog[i]) for correspond_dialog in samples[\"correspond_dialog\"] for i in\n",
    "\t\t range(len(correspond_dialog))])\n",
    "\n",
    "\tsample_length = len(model_inputs)\n",
    "\tfor i in range(sample_length):\n",
    "\t\tsample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "\t\tlabel_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
    "\n",
    "\t\tmodel_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
    "\t\tlabels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
    "\t\tmodel_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
    "\n",
    "\tfor i in range(sample_length):\n",
    "\t\tsample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "\t\tlabel_input_ids = labels[\"input_ids\"][i]\n",
    "\n",
    "\t\tpad_length = max_sequence_length - len(sample_input_ids)\n",
    "\t\tmodel_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * pad_length + sample_input_ids\n",
    "\t\tmodel_inputs[\"attention_mask\"][i] = [0] * pad_length + model_inputs[\"attention_mask\"][i]\n",
    "\t\tlabels[\"input_ids\"][i] = [-100] * pad_length + label_input_ids\n",
    "\n",
    "\t\tmodel_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_sequence_length])\n",
    "\t\tmodel_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_sequence_length])\n",
    "\t\tlabels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_sequence_length])\n",
    "\n",
    "\tmodel_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "\treturn model_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:41.324637Z",
     "start_time": "2023-10-25T17:52:41.322056Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Running tokenizer on dataset (num_proc=8):   0%|          | 0/11118 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4273244fdf5c429db504312334db19c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Running tokenizer on dataset (num_proc=8):   0%|          | 0/1000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a35b9fe66a624805b2a72c476d6460cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Running tokenizer on dataset (num_proc=8):   0%|          | 0/1000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78ee0235ca4e441aacbb9c3b0eaf0630"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_datasets = dataset.map(\n",
    "\tpreprocess,\n",
    "\tbatched=True,\n",
    "\tnum_proc=8,\n",
    "\tremove_columns=dataset[\"train\"].column_names,\n",
    "\tload_from_cache_file=False,\n",
    "\tdesc=\"Running tokenizer on dataset\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:44.338479Z",
     "start_time": "2023-10-25T17:52:41.324071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_dataset = processed_datasets[\"train\"]\n",
    "eval_dataset = processed_datasets[\"test\"]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=default_data_collator, shuffle=True, pin_memory=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:52:44.344316Z",
     "start_time": "2023-10-25T17:52:44.340162Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd7b117166444ee79a05481e955a6200"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 32,768 || all params: 6,738,448,384 || trainable%: 0.0004862840543203603\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model = get_peft_model(model, model_config)\n",
    "print(model.print_trainable_parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:55:39.043358Z",
     "start_time": "2023-10-25T17:52:44.343443Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "\toptimizer=optimizer,\n",
    "\tnum_warmup_steps=0,\n",
    "\tnum_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:55:39.081780Z",
     "start_time": "2023-10-25T17:55:39.053557Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/76052 [03:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (49) to match target batch_size (20).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(train_dataloader)):\n\u001B[1;32m      7\u001B[0m \tbatch \u001B[38;5;241m=\u001B[39m { k: v\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mitems() }\n\u001B[0;32m----> 8\u001B[0m \toutputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \tloss \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mloss\n\u001B[1;32m     10\u001B[0m \ttotal_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mfloat()\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/peft/peft_model.py:966\u001B[0m, in \u001B[0;36mPeftModelForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m    964\u001B[0m prompts \u001B[38;5;241m=\u001B[39m prompts\u001B[38;5;241m.\u001B[39mto(inputs_embeds\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m    965\u001B[0m inputs_embeds \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((prompts, inputs_embeds), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 966\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1070\u001B[0m, in \u001B[0;36mLlamaForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1068\u001B[0m     \u001B[38;5;66;03m# Enable model parallelism\u001B[39;00m\n\u001B[1;32m   1069\u001B[0m     shift_labels \u001B[38;5;241m=\u001B[39m shift_labels\u001B[38;5;241m.\u001B[39mto(shift_logits\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m-> 1070\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_fct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshift_logits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshift_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1072\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict:\n\u001B[1;32m   1073\u001B[0m     output \u001B[38;5;241m=\u001B[39m (logits,) \u001B[38;5;241m+\u001B[39m outputs[\u001B[38;5;241m1\u001B[39m:]\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/loss.py:1179\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m   1178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m-> 1179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1180\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1181\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/functional.py:3053\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3051\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3052\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3053\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: Expected input batch_size (49) to match target batch_size (20)."
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\tmodel.train()\n",
    "\ttotal_loss = 0\n",
    "\tfor step, batch in enumerate(tqdm(train_dataloader)):\n",
    "\t\tbatch = {k: v.to(device) for k, v in batch.items()}\n",
    "\t\toutputs = model(**batch)\n",
    "\t\tloss = outputs.loss\n",
    "\t\ttotal_loss += loss.detach().float()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\tlr_scheduler.step()\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\tmodel.eval()\n",
    "\teval_loss = 0\n",
    "\teval_preds = []\n",
    "\tfor step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "\t\tbatch = {k: v.to(device) for k, v in batch.items()}\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutputs = model(**batch)\n",
    "\t\tloss = outputs.loss\n",
    "\t\teval_loss += loss.detach().float()\n",
    "\t\teval_preds.extend(\n",
    "\t\t\ttokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "\t\t)\n",
    "\n",
    "\teval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "\teval_ppl = torch.exp(eval_epoch_loss)\n",
    "\ttrain_epoch_loss = total_loss / len(train_dataloader)\n",
    "\ttrain_ppl = torch.exp(train_epoch_loss)\n",
    "\tprint(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:58:59.412380Z",
     "start_time": "2023-10-25T17:55:39.061235Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:58:59.430823Z",
     "start_time": "2023-10-25T17:58:59.430025Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b068cf88dc54ccaa2302c8dde964627": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0b74dabdbfc6475ca1751d6d9ec19eaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "14673c2e817d406f8c014a37ab9a8519": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "153bbe09665245ce860a285607c47d88": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "18722a725e3a41a49d776fe219e5add8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_31c239f6606c4960a0a696a1150b162c",
       "style": "IPY_MODEL_e37513b55d4b47dca420ff1c2613ac92",
       "value": " 4.85k/4.85k [00:00&lt;00:00, 456kB/s]"
      }
     },
     "1967873fbd7b45ae99ddbd1a819a8b18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1bc06efee12c4fc882208400e08f5f4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6cbb45f3e4ca4a178202a3a402b9b4b7",
       "style": "IPY_MODEL_6ef677a267dd425aada95bbf587ecd36",
       "value": " 7.27k/7.27k [00:00&lt;00:00, 562kB/s]"
      }
     },
     "1c98b7631f404c16b9061c469989dbb4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1d73349739704d1180a536b3d63832cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_edd23727b27a49ae9b4965ffb47ddbbb",
       "style": "IPY_MODEL_8e070069a73c47739a625001271284ef",
       "value": "Generating train split: 100%"
      }
     },
     "20825c622aaa4f58a85e2d335ae18173": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "21abd17325534f4795469f2939ca3294": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "226b0d9d6d9a465ab92d6f43693a988b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8f69f06af2f84fe9a73330278678cef1",
       "style": "IPY_MODEL_0b74dabdbfc6475ca1751d6d9ec19eaf",
       "value": " 4.48M/4.48M [00:03&lt;00:00, 1.51MB/s]"
      }
     },
     "22c6d82643f848019e764643b9b901e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "243fd0b1f6f14570902ca049a2e0902d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d770f59352084362a20d0ac18cb5bda4",
       "max": 4475921,
       "style": "IPY_MODEL_ae5e6c54adc5472c90473daa9264f759",
       "value": 4475921
      }
     },
     "253389ecbc4c4f288f332bc3505fdf74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2cb6520f0d1b427d94e6738ea4ddfe68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2e02748e06ae4b28a872eaf1b28ba935": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "30d4aa92372542b0b3c8402cf2b4bec2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "31c239f6606c4960a0a696a1150b162c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "335237366fe74fe1bbea8670d4677111": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_df4a03ac927e43be8247e906ea800063",
       "style": "IPY_MODEL_cbc869bd92e84e0986412405f1dec6c3",
       "value": "Downloading readme: 100%"
      }
     },
     "3ce7df172c0241768e0cf8afe14ac3d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3de7ac2037984bd1b9f326d2d738ae16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4125bbd3fabd42ae9ed19635e3eb8f50",
        "IPY_MODEL_838c9f17c064497ba5f9b338a04a3333",
        "IPY_MODEL_5ec52d622bfd4f67a8830d62633f5300"
       ],
       "layout": "IPY_MODEL_cc7a083c3b054697843a932bd3ef8551"
      }
     },
     "3eba154026e84946b051454883e3e7ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4125bbd3fabd42ae9ed19635e3eb8f50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5a8ee30be40347d7884ff294df38d3c0",
       "style": "IPY_MODEL_2cb6520f0d1b427d94e6738ea4ddfe68",
       "value": "Downloading metadata: 100%"
      }
     },
     "42b0d9de5db5414183fddfdd84ff1bb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "503eeb4e23844dacacb91f7b7a985579": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_335237366fe74fe1bbea8670d4677111",
        "IPY_MODEL_b9211b66fcf745ca8d6be4015067306d",
        "IPY_MODEL_1bc06efee12c4fc882208400e08f5f4d"
       ],
       "layout": "IPY_MODEL_85b48b5e64444fcfaa0b7d0ee523374a"
      }
     },
     "5594156a1c984ec38cdd5ebed1a1b4de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5a8ee30be40347d7884ff294df38d3c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5c4b783063fb40c4a7d0a95f2bfc388b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d4953a3803fe44fcbcd36f73fafe4d1b",
       "style": "IPY_MODEL_1967873fbd7b45ae99ddbd1a819a8b18",
       "value": "Downloading builder script: 100%"
      }
     },
     "5ce80f7a3471447f9de270e34a097607": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6e8e464034984b3598f9d1caf549fd96",
       "style": "IPY_MODEL_e27d2aa60d4c4411a4bb9ba9a27c6dce",
       "value": "Downloading data: 100%"
      }
     },
     "5ec52d622bfd4f67a8830d62633f5300": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_22c6d82643f848019e764643b9b901e2",
       "style": "IPY_MODEL_253389ecbc4c4f288f332bc3505fdf74",
       "value": " 2.49k/2.49k [00:00&lt;00:00, 191kB/s]"
      }
     },
     "68e25ff50906468d9eaafdf8ab37a721": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6cbb45f3e4ca4a178202a3a402b9b4b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6e8e464034984b3598f9d1caf549fd96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6ebd259e5e0e4ec4baa1eb174ecbe496": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6ef677a267dd425aada95bbf587ecd36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "73ae861791794376927fc9087e252cec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "74e4ed68b9fc4ee0b89dcdfa1cf23769": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c0ebb884a4f4458b89dd79703bc9c31a",
       "max": 1000,
       "style": "IPY_MODEL_77758cd07d84474f97f3624fca386ce0",
       "value": 1000
      }
     },
     "77758cd07d84474f97f3624fca386ce0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7afc7f3491234b71a6f3199e65dd6cef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7b283f9282e34090bc6c27d5b8f951f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1d73349739704d1180a536b3d63832cb",
        "IPY_MODEL_e0a545695cc04cbf9490aec954119158",
        "IPY_MODEL_ccf835967bd7493e80de94a6469af99d"
       ],
       "layout": "IPY_MODEL_d8d047d755204d34934dce01246b1645"
      }
     },
     "7bf1c47d45044ceb9b0e28bf16b473a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "831d9afd71b84ccbae408482ffd6d436": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0b068cf88dc54ccaa2302c8dde964627",
       "style": "IPY_MODEL_a9f08d6133a4440ab7a32f1d49679a70",
       "value": " 1000/1000 [00:00&lt;00:00, 27222.48 examples/s]"
      }
     },
     "838c9f17c064497ba5f9b338a04a3333": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_fc863b5ddbc44871bfe4003334b2f78f",
       "max": 2489,
       "style": "IPY_MODEL_68e25ff50906468d9eaafdf8ab37a721",
       "value": 2489
      }
     },
     "8391fd72391e45fca3beb75d5bc62f49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_21abd17325534f4795469f2939ca3294",
       "style": "IPY_MODEL_5594156a1c984ec38cdd5ebed1a1b4de",
       "value": "Generating validation split: 100%"
      }
     },
     "85b48b5e64444fcfaa0b7d0ee523374a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8771aa97674b437d87d0ec72c3c2129c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_42b0d9de5db5414183fddfdd84ff1bb6",
       "style": "IPY_MODEL_6ebd259e5e0e4ec4baa1eb174ecbe496",
       "value": "Generating test split: 100%"
      }
     },
     "8e070069a73c47739a625001271284ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8f69f06af2f84fe9a73330278678cef1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "96ee09d822b94431945bc8d4136f63a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1c98b7631f404c16b9061c469989dbb4",
       "style": "IPY_MODEL_bf9e3e04545d443eab84d20a7560519a",
       "value": " 1000/1000 [00:00&lt;00:00, 27961.84 examples/s]"
      }
     },
     "98e41e7670354a05abb23c8596b76a43": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a60bb3ddf86c4f4b892e8f2d2dd66359": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a9f08d6133a4440ab7a32f1d49679a70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ae5e6c54adc5472c90473daa9264f759": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b9211b66fcf745ca8d6be4015067306d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_14673c2e817d406f8c014a37ab9a8519",
       "max": 7270,
       "style": "IPY_MODEL_e3718a6631384dc494db45325d60f8cc",
       "value": 7270
      }
     },
     "bda1eeb24fe84a95a04cf832d70a7123": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bf9e3e04545d443eab84d20a7560519a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c06b7347151449d9ae640ba87f8ac836": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c0bf33ebab5144a5b8d28513f0d18423": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c0ebb884a4f4458b89dd79703bc9c31a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c8e1e0a4ff004dffba7e844fb865f32b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cbc869bd92e84e0986412405f1dec6c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cc72a9f8e2a24fbb98963fdb03cee6c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ed8da65ef211455ab0e5955f9ad81a20",
       "style": "IPY_MODEL_a60bb3ddf86c4f4b892e8f2d2dd66359",
       "value": "Computing checksums: 100%"
      }
     },
     "cc7a083c3b054697843a932bd3ef8551": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ccf835967bd7493e80de94a6469af99d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f8015f3a444249edbf21bf3378c10b16",
       "style": "IPY_MODEL_73ae861791794376927fc9087e252cec",
       "value": " 11118/11118 [00:00&lt;00:00, 29358.34 examples/s]"
      }
     },
     "d48104a276814cc08e0ab858e5972988": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cc72a9f8e2a24fbb98963fdb03cee6c6",
        "IPY_MODEL_e5c159cca76a425b8133b10b3d6c2830",
        "IPY_MODEL_ecc21a0d2ef24b2abbcbffb9926b5023"
       ],
       "layout": "IPY_MODEL_153bbe09665245ce860a285607c47d88"
      }
     },
     "d4953a3803fe44fcbcd36f73fafe4d1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d759b465aee647a2bf894e1fab1d4005": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d770f59352084362a20d0ac18cb5bda4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d8d047d755204d34934dce01246b1645": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dd0dbad5297043e4be3dad1ef1a7aa45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5ce80f7a3471447f9de270e34a097607",
        "IPY_MODEL_243fd0b1f6f14570902ca049a2e0902d",
        "IPY_MODEL_226b0d9d6d9a465ab92d6f43693a988b"
       ],
       "layout": "IPY_MODEL_bda1eeb24fe84a95a04cf832d70a7123"
      }
     },
     "df4a03ac927e43be8247e906ea800063": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e0a545695cc04cbf9490aec954119158": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3eba154026e84946b051454883e3e7ef",
       "max": 11118,
       "style": "IPY_MODEL_2e02748e06ae4b28a872eaf1b28ba935",
       "value": 11118
      }
     },
     "e27d2aa60d4c4411a4bb9ba9a27c6dce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e3718a6631384dc494db45325d60f8cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e37513b55d4b47dca420ff1c2613ac92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e5c159cca76a425b8133b10b3d6c2830": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c06b7347151449d9ae640ba87f8ac836",
       "max": 1,
       "style": "IPY_MODEL_7bf1c47d45044ceb9b0e28bf16b473a8",
       "value": 1
      }
     },
     "ecc21a0d2ef24b2abbcbffb9926b5023": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f25d2242e77844049689ac0847990d2a",
       "style": "IPY_MODEL_30d4aa92372542b0b3c8402cf2b4bec2",
       "value": " 1/1 [00:00&lt;00:00, 116.28it/s]"
      }
     },
     "ed8da65ef211455ab0e5955f9ad81a20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "edd23727b27a49ae9b4965ffb47ddbbb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f25d2242e77844049689ac0847990d2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f2f864d8a5d3414ea9f70bbd3fce230e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_20825c622aaa4f58a85e2d335ae18173",
       "max": 1000,
       "style": "IPY_MODEL_c8e1e0a4ff004dffba7e844fb865f32b",
       "value": 1000
      }
     },
     "f8015f3a444249edbf21bf3378c10b16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f904a27a7136468d9405e18a9e188fcc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_98e41e7670354a05abb23c8596b76a43",
       "max": 4851,
       "style": "IPY_MODEL_3ce7df172c0241768e0cf8afe14ac3d2",
       "value": 4851
      }
     },
     "f99299987f204b10a13c4678ac4dc00f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8771aa97674b437d87d0ec72c3c2129c",
        "IPY_MODEL_74e4ed68b9fc4ee0b89dcdfa1cf23769",
        "IPY_MODEL_96ee09d822b94431945bc8d4136f63a0"
       ],
       "layout": "IPY_MODEL_c0bf33ebab5144a5b8d28513f0d18423"
      }
     },
     "fc863b5ddbc44871bfe4003334b2f78f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ffa12f0ac90141d9b93bfa07b695b2d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5c4b783063fb40c4a7d0a95f2bfc388b",
        "IPY_MODEL_f904a27a7136468d9405e18a9e188fcc",
        "IPY_MODEL_18722a725e3a41a49d776fe219e5add8"
       ],
       "layout": "IPY_MODEL_7afc7f3491234b71a6f3199e65dd6cef"
      }
     },
     "ffcf4e969e974032ad84095d3f742ade": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8391fd72391e45fca3beb75d5bc62f49",
        "IPY_MODEL_f2f864d8a5d3414ea9f70bbd3fce230e",
        "IPY_MODEL_831d9afd71b84ccbae408482ffd6d436"
       ],
       "layout": "IPY_MODEL_d759b465aee647a2bf894e1fab1d4005"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
