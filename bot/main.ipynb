{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:45.741563Z",
     "start_time": "2023-10-24T17:28:43.289244Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -Uq peft transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:50.358375Z",
     "start_time": "2023-10-24T17:28:45.741927Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:50.364696Z",
     "start_time": "2023-10-24T17:28:50.358697Z"
    }
   },
   "outputs": [],
   "source": [
    "device: str = \"mps\"\n",
    "model_name: str = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:50.365087Z",
     "start_time": "2023-10-24T17:28:50.361101Z"
    }
   },
   "outputs": [],
   "source": [
    "model_config = PromptTuningConfig(\n",
    "\ttask_type=TaskType.CAUSAL_LM,\n",
    "\tprompt_tuning_init=PromptTuningInit.TEXT,\n",
    "\tnum_virtual_tokens=8,\n",
    "\tprompt_tuning_init_text=\"Classify the emotion in the following sentence:\",\n",
    "\ttokenizer_name_or_path=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:50.370392Z",
     "start_time": "2023-10-24T17:28:50.365183Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name: str = \"daily_dialog\"\n",
    "max_sequence_length = 4096\n",
    "learning_rate = 3e-2\n",
    "num_epochs = 50\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:53.469641Z",
     "start_time": "2023-10-24T17:28:50.367352Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "emotions: list = list(dataset[\"train\"].features[\"emotion\"].feature.names)\n",
    "emotions[0] = \"neutral\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:53.476611Z",
     "start_time": "2023-10-24T17:28:53.470219Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "\tlambda samples: {\n",
    "\t\t\"previous_dialog\": [sample[:-1] for sample in samples[\"dialog\"]]\n",
    "\t},\n",
    "\tbatched=True,\n",
    "\tnum_proc=8\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:53.517195Z",
     "start_time": "2023-10-24T17:28:53.473038Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "\tlambda samples: {\n",
    "\t\t\"correspond_dialog\": [sample[1:] for sample in samples[\"dialog\"]]\n",
    "\t},\n",
    "\tbatched=True,\n",
    "\tnum_proc=8\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:53.554833Z",
     "start_time": "2023-10-24T17:28:53.518367Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "\tlambda samples: {\n",
    "\t\t\"current_emotion\": [[emotions[label] for label in sample][:-1] for sample in samples[\"emotion\"]]\n",
    "\t},\n",
    "\tbatched=True,\n",
    "\tnum_proc=8\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:53.593954Z",
     "start_time": "2023-10-24T17:28:53.556714Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "\tlambda samples: {\n",
    "\t\t\"correspond_emotion\": [[emotions[label] for label in sample][1:] for sample in samples[\"emotion\"]]\n",
    "\t},\n",
    "\tbatched=True,\n",
    "\tnum_proc=8\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:53.637944Z",
     "start_time": "2023-10-24T17:28:53.595893Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'dialog': ['Say , Jim , how about going for a few beers after dinner ? ',\n  ' You know that is tempting but is really not good for our fitness . ',\n  ' What do you mean ? It will help us to relax . ',\n  \" Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ? \",\n  \" I guess you are right.But what shall we do ? I don't feel like sitting at home . \",\n  ' I suggest a walk over to the gym where we can play singsong and meet some of our friends . ',\n  \" That's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \",\n  ' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . ',\n  \" Good.Let ' s go now . \",\n  ' All right . '],\n 'act': [3, 4, 2, 2, 2, 3, 4, 1, 3, 4],\n 'emotion': [0, 0, 0, 0, 0, 0, 4, 4, 4, 4],\n 'previous_dialog': ['Say , Jim , how about going for a few beers after dinner ? ',\n  ' You know that is tempting but is really not good for our fitness . ',\n  ' What do you mean ? It will help us to relax . ',\n  \" Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ? \",\n  \" I guess you are right.But what shall we do ? I don't feel like sitting at home . \",\n  ' I suggest a walk over to the gym where we can play singsong and meet some of our friends . ',\n  \" That's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \",\n  ' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . ',\n  \" Good.Let ' s go now . \"],\n 'correspond_dialog': [' You know that is tempting but is really not good for our fitness . ',\n  ' What do you mean ? It will help us to relax . ',\n  \" Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ? \",\n  \" I guess you are right.But what shall we do ? I don't feel like sitting at home . \",\n  ' I suggest a walk over to the gym where we can play singsong and meet some of our friends . ',\n  \" That's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \",\n  ' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . ',\n  \" Good.Let ' s go now . \",\n  ' All right . '],\n 'current_emotion': ['neutral',\n  'neutral',\n  'neutral',\n  'neutral',\n  'neutral',\n  'neutral',\n  'happiness',\n  'happiness',\n  'happiness'],\n 'correspond_emotion': ['neutral',\n  'neutral',\n  'neutral',\n  'neutral',\n  'neutral',\n  'happiness',\n  'happiness',\n  'happiness',\n  'happiness']}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:53.647128Z",
     "start_time": "2023-10-24T17:28:53.641921Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:54.274426Z",
     "start_time": "2023-10-24T17:28:53.644444Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id if (tokenizer.pad_token_id is None) else tokenizer.pad_token_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:54.279314Z",
     "start_time": "2023-10-24T17:28:54.276462Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_label_max_length: int = max([len(tokenizer(label)[\"input_ids\"]) for label in emotions])\n",
    "emotion_label_max_length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:54.284020Z",
     "start_time": "2023-10-24T17:28:54.279095Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def preprocess(samples):\n",
    "\tmodel_inputs = tokenizer([\n",
    "\t\tf\"previous_dialog: {sample[0][i]}, correspond_emotion: {sample[1][i]} => correspond_dialog: \"\n",
    "\t\tfor sample in zip(samples[\"previous_dialog\"], samples[\"correspond_emotion\"]) for i\n",
    "\t\tin range(len(sample[0]))])\n",
    "\treal_outputs = tokenizer(\n",
    "\t\t[str(correspond_dialog[i]) for correspond_dialog in samples[\"correspond_dialog\"] for i in\n",
    "\t\t range(len(correspond_dialog))])\n",
    "\n",
    "\tsample_length = len(model_inputs)\n",
    "\tfor i in range(sample_length):\n",
    "\t\tsample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "\t\tlabel_input_ids = real_outputs[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
    "\n",
    "\t\tmodel_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
    "\t\treal_outputs[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
    "\t\tmodel_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
    "\n",
    "\tfor i in range(sample_length):\n",
    "\t\tsample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "\t\tlabel_input_ids = real_outputs[\"input_ids\"][i]\n",
    "\n",
    "\t\tpad_length = max_sequence_length - len(sample_input_ids)\n",
    "\t\tmodel_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * pad_length + sample_input_ids\n",
    "\t\tmodel_inputs[\"attention_mask\"][i] = [0] * pad_length + model_inputs[\"attention_mask\"][i]\n",
    "\t\treal_outputs[\"input_ids\"][i] = [-100] * pad_length + label_input_ids\n",
    "\n",
    "\t\tmodel_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_sequence_length])\n",
    "\t\tmodel_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_sequence_length])\n",
    "\t\treal_outputs[\"input_ids\"][i] = torch.tensor(real_outputs[\"input_ids\"][i][:max_sequence_length])\n",
    "\n",
    "\tmodel_inputs[\"real_outputs\"] = real_outputs[\"input_ids\"]\n",
    "\n",
    "\treturn model_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:54.288787Z",
     "start_time": "2023-10-24T17:28:54.285672Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Running tokenizer on dataset (num_proc=8):   0%|          | 0/11118 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4cc701c17cb455dabccd388c5ebfc93"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Running tokenizer on dataset (num_proc=8):   0%|          | 0/1000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07352cf3159e46c2af7689ff4d651967"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Running tokenizer on dataset (num_proc=8):   0%|          | 0/1000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f18462ac6a954cb0be4a42a3d5744d03"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_datasets = dataset.map(\n",
    "\tpreprocess,\n",
    "\tbatched=True,\n",
    "\tnum_proc=8,\n",
    "\tremove_columns=dataset[\"train\"].column_names,\n",
    "\tload_from_cache_file=False,\n",
    "\tdesc=\"Running tokenizer on dataset\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:57.780112Z",
     "start_time": "2023-10-24T17:28:54.304873Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_dataset = processed_datasets[\"train\"]\n",
    "eval_dataset = processed_datasets[\"test\"]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=default_data_collator, shuffle=True, pin_memory=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:28:57.785243Z",
     "start_time": "2023-10-24T17:28:57.781383Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "796316d71d39432fb0266836de517705"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 32,768 || all params: 6,738,448,384 || trainable%: 0.0004862840543203603\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model = get_peft_model(model, model_config)\n",
    "print(model.print_trainable_parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:31:47.883928Z",
     "start_time": "2023-10-24T17:28:57.783987Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "\toptimizer=optimizer,\n",
    "\tnum_warmup_steps=0,\n",
    "\tnum_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:31:47.994705Z",
     "start_time": "2023-10-24T17:31:47.865287Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 17.75 GB, other allocations: 323.68 MB, max allowed: 18.13 GB). Tried to allocate 172.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[1;32m      4\u001B[0m \tmodel\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1156\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1157\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[0;32m-> 1160\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 810\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 810\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "    \u001B[0;31m[... skipping similar frames: Module._apply at line 810 (3 times)]\u001B[0m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 810\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:833\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    829\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 833\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    835\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[0;32m~/.local/share/pyenv/versions/3.11.6/envs/chat-bot/lib/python3.11/site-packages/torch/nn/modules/module.py:1158\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1157\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m-> 1158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS backend out of memory (MPS allocated: 17.75 GB, other allocations: 323.68 MB, max allowed: 18.13 GB). Tried to allocate 172.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\tmodel.train()\n",
    "\ttotal_loss = 0\n",
    "\tfor step, batch in enumerate(tqdm(train_dataloader)):\n",
    "\t\tbatch = { k: v.to(device) for k, v in batch.items() }\n",
    "\t\toutputs = model(**batch)\n",
    "\t\tloss = outputs.loss\n",
    "\t\ttotal_loss += loss.detach().float()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\tlr_scheduler.step()\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\tmodel.eval()\n",
    "\teval_loss = 0\n",
    "\teval_preds = []\n",
    "\tfor step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "\t\tbatch = { k: v.to(device) for k, v in batch.items() }\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutputs = model(**batch)\n",
    "\t\tloss = outputs.loss\n",
    "\t\teval_loss += loss.detach().float()\n",
    "\t\teval_preds.extend(\n",
    "\t\t\ttokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "\t\t)\n",
    "\n",
    "\teval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "\teval_ppl = torch.exp(eval_epoch_loss)\n",
    "\ttrain_epoch_loss = total_loss / len(train_dataloader)\n",
    "\ttrain_ppl = torch.exp(train_epoch_loss)\n",
    "\tprint(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T17:33:58.870803Z",
     "start_time": "2023-10-24T17:31:47.874901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-24T17:33:58.845773Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b068cf88dc54ccaa2302c8dde964627": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0b74dabdbfc6475ca1751d6d9ec19eaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "14673c2e817d406f8c014a37ab9a8519": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "153bbe09665245ce860a285607c47d88": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "18722a725e3a41a49d776fe219e5add8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_31c239f6606c4960a0a696a1150b162c",
       "style": "IPY_MODEL_e37513b55d4b47dca420ff1c2613ac92",
       "value": " 4.85k/4.85k [00:00&lt;00:00, 456kB/s]"
      }
     },
     "1967873fbd7b45ae99ddbd1a819a8b18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1bc06efee12c4fc882208400e08f5f4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6cbb45f3e4ca4a178202a3a402b9b4b7",
       "style": "IPY_MODEL_6ef677a267dd425aada95bbf587ecd36",
       "value": " 7.27k/7.27k [00:00&lt;00:00, 562kB/s]"
      }
     },
     "1c98b7631f404c16b9061c469989dbb4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1d73349739704d1180a536b3d63832cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_edd23727b27a49ae9b4965ffb47ddbbb",
       "style": "IPY_MODEL_8e070069a73c47739a625001271284ef",
       "value": "Generating train split: 100%"
      }
     },
     "20825c622aaa4f58a85e2d335ae18173": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "21abd17325534f4795469f2939ca3294": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "226b0d9d6d9a465ab92d6f43693a988b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8f69f06af2f84fe9a73330278678cef1",
       "style": "IPY_MODEL_0b74dabdbfc6475ca1751d6d9ec19eaf",
       "value": " 4.48M/4.48M [00:03&lt;00:00, 1.51MB/s]"
      }
     },
     "22c6d82643f848019e764643b9b901e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "243fd0b1f6f14570902ca049a2e0902d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d770f59352084362a20d0ac18cb5bda4",
       "max": 4475921,
       "style": "IPY_MODEL_ae5e6c54adc5472c90473daa9264f759",
       "value": 4475921
      }
     },
     "253389ecbc4c4f288f332bc3505fdf74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2cb6520f0d1b427d94e6738ea4ddfe68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2e02748e06ae4b28a872eaf1b28ba935": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "30d4aa92372542b0b3c8402cf2b4bec2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "31c239f6606c4960a0a696a1150b162c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "335237366fe74fe1bbea8670d4677111": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_df4a03ac927e43be8247e906ea800063",
       "style": "IPY_MODEL_cbc869bd92e84e0986412405f1dec6c3",
       "value": "Downloading readme: 100%"
      }
     },
     "3ce7df172c0241768e0cf8afe14ac3d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3de7ac2037984bd1b9f326d2d738ae16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4125bbd3fabd42ae9ed19635e3eb8f50",
        "IPY_MODEL_838c9f17c064497ba5f9b338a04a3333",
        "IPY_MODEL_5ec52d622bfd4f67a8830d62633f5300"
       ],
       "layout": "IPY_MODEL_cc7a083c3b054697843a932bd3ef8551"
      }
     },
     "3eba154026e84946b051454883e3e7ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4125bbd3fabd42ae9ed19635e3eb8f50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5a8ee30be40347d7884ff294df38d3c0",
       "style": "IPY_MODEL_2cb6520f0d1b427d94e6738ea4ddfe68",
       "value": "Downloading metadata: 100%"
      }
     },
     "42b0d9de5db5414183fddfdd84ff1bb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "503eeb4e23844dacacb91f7b7a985579": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_335237366fe74fe1bbea8670d4677111",
        "IPY_MODEL_b9211b66fcf745ca8d6be4015067306d",
        "IPY_MODEL_1bc06efee12c4fc882208400e08f5f4d"
       ],
       "layout": "IPY_MODEL_85b48b5e64444fcfaa0b7d0ee523374a"
      }
     },
     "5594156a1c984ec38cdd5ebed1a1b4de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5a8ee30be40347d7884ff294df38d3c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5c4b783063fb40c4a7d0a95f2bfc388b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d4953a3803fe44fcbcd36f73fafe4d1b",
       "style": "IPY_MODEL_1967873fbd7b45ae99ddbd1a819a8b18",
       "value": "Downloading builder script: 100%"
      }
     },
     "5ce80f7a3471447f9de270e34a097607": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6e8e464034984b3598f9d1caf549fd96",
       "style": "IPY_MODEL_e27d2aa60d4c4411a4bb9ba9a27c6dce",
       "value": "Downloading data: 100%"
      }
     },
     "5ec52d622bfd4f67a8830d62633f5300": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_22c6d82643f848019e764643b9b901e2",
       "style": "IPY_MODEL_253389ecbc4c4f288f332bc3505fdf74",
       "value": " 2.49k/2.49k [00:00&lt;00:00, 191kB/s]"
      }
     },
     "68e25ff50906468d9eaafdf8ab37a721": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6cbb45f3e4ca4a178202a3a402b9b4b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6e8e464034984b3598f9d1caf549fd96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6ebd259e5e0e4ec4baa1eb174ecbe496": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6ef677a267dd425aada95bbf587ecd36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "73ae861791794376927fc9087e252cec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "74e4ed68b9fc4ee0b89dcdfa1cf23769": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c0ebb884a4f4458b89dd79703bc9c31a",
       "max": 1000,
       "style": "IPY_MODEL_77758cd07d84474f97f3624fca386ce0",
       "value": 1000
      }
     },
     "77758cd07d84474f97f3624fca386ce0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7afc7f3491234b71a6f3199e65dd6cef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7b283f9282e34090bc6c27d5b8f951f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1d73349739704d1180a536b3d63832cb",
        "IPY_MODEL_e0a545695cc04cbf9490aec954119158",
        "IPY_MODEL_ccf835967bd7493e80de94a6469af99d"
       ],
       "layout": "IPY_MODEL_d8d047d755204d34934dce01246b1645"
      }
     },
     "7bf1c47d45044ceb9b0e28bf16b473a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "831d9afd71b84ccbae408482ffd6d436": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0b068cf88dc54ccaa2302c8dde964627",
       "style": "IPY_MODEL_a9f08d6133a4440ab7a32f1d49679a70",
       "value": " 1000/1000 [00:00&lt;00:00, 27222.48 examples/s]"
      }
     },
     "838c9f17c064497ba5f9b338a04a3333": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_fc863b5ddbc44871bfe4003334b2f78f",
       "max": 2489,
       "style": "IPY_MODEL_68e25ff50906468d9eaafdf8ab37a721",
       "value": 2489
      }
     },
     "8391fd72391e45fca3beb75d5bc62f49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_21abd17325534f4795469f2939ca3294",
       "style": "IPY_MODEL_5594156a1c984ec38cdd5ebed1a1b4de",
       "value": "Generating validation split: 100%"
      }
     },
     "85b48b5e64444fcfaa0b7d0ee523374a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8771aa97674b437d87d0ec72c3c2129c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_42b0d9de5db5414183fddfdd84ff1bb6",
       "style": "IPY_MODEL_6ebd259e5e0e4ec4baa1eb174ecbe496",
       "value": "Generating test split: 100%"
      }
     },
     "8e070069a73c47739a625001271284ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8f69f06af2f84fe9a73330278678cef1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "96ee09d822b94431945bc8d4136f63a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1c98b7631f404c16b9061c469989dbb4",
       "style": "IPY_MODEL_bf9e3e04545d443eab84d20a7560519a",
       "value": " 1000/1000 [00:00&lt;00:00, 27961.84 examples/s]"
      }
     },
     "98e41e7670354a05abb23c8596b76a43": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a60bb3ddf86c4f4b892e8f2d2dd66359": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a9f08d6133a4440ab7a32f1d49679a70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ae5e6c54adc5472c90473daa9264f759": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b9211b66fcf745ca8d6be4015067306d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_14673c2e817d406f8c014a37ab9a8519",
       "max": 7270,
       "style": "IPY_MODEL_e3718a6631384dc494db45325d60f8cc",
       "value": 7270
      }
     },
     "bda1eeb24fe84a95a04cf832d70a7123": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bf9e3e04545d443eab84d20a7560519a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c06b7347151449d9ae640ba87f8ac836": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c0bf33ebab5144a5b8d28513f0d18423": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c0ebb884a4f4458b89dd79703bc9c31a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c8e1e0a4ff004dffba7e844fb865f32b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cbc869bd92e84e0986412405f1dec6c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cc72a9f8e2a24fbb98963fdb03cee6c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ed8da65ef211455ab0e5955f9ad81a20",
       "style": "IPY_MODEL_a60bb3ddf86c4f4b892e8f2d2dd66359",
       "value": "Computing checksums: 100%"
      }
     },
     "cc7a083c3b054697843a932bd3ef8551": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ccf835967bd7493e80de94a6469af99d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f8015f3a444249edbf21bf3378c10b16",
       "style": "IPY_MODEL_73ae861791794376927fc9087e252cec",
       "value": " 11118/11118 [00:00&lt;00:00, 29358.34 examples/s]"
      }
     },
     "d48104a276814cc08e0ab858e5972988": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cc72a9f8e2a24fbb98963fdb03cee6c6",
        "IPY_MODEL_e5c159cca76a425b8133b10b3d6c2830",
        "IPY_MODEL_ecc21a0d2ef24b2abbcbffb9926b5023"
       ],
       "layout": "IPY_MODEL_153bbe09665245ce860a285607c47d88"
      }
     },
     "d4953a3803fe44fcbcd36f73fafe4d1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d759b465aee647a2bf894e1fab1d4005": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d770f59352084362a20d0ac18cb5bda4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d8d047d755204d34934dce01246b1645": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dd0dbad5297043e4be3dad1ef1a7aa45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5ce80f7a3471447f9de270e34a097607",
        "IPY_MODEL_243fd0b1f6f14570902ca049a2e0902d",
        "IPY_MODEL_226b0d9d6d9a465ab92d6f43693a988b"
       ],
       "layout": "IPY_MODEL_bda1eeb24fe84a95a04cf832d70a7123"
      }
     },
     "df4a03ac927e43be8247e906ea800063": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e0a545695cc04cbf9490aec954119158": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3eba154026e84946b051454883e3e7ef",
       "max": 11118,
       "style": "IPY_MODEL_2e02748e06ae4b28a872eaf1b28ba935",
       "value": 11118
      }
     },
     "e27d2aa60d4c4411a4bb9ba9a27c6dce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e3718a6631384dc494db45325d60f8cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e37513b55d4b47dca420ff1c2613ac92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e5c159cca76a425b8133b10b3d6c2830": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c06b7347151449d9ae640ba87f8ac836",
       "max": 1,
       "style": "IPY_MODEL_7bf1c47d45044ceb9b0e28bf16b473a8",
       "value": 1
      }
     },
     "ecc21a0d2ef24b2abbcbffb9926b5023": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f25d2242e77844049689ac0847990d2a",
       "style": "IPY_MODEL_30d4aa92372542b0b3c8402cf2b4bec2",
       "value": " 1/1 [00:00&lt;00:00, 116.28it/s]"
      }
     },
     "ed8da65ef211455ab0e5955f9ad81a20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "edd23727b27a49ae9b4965ffb47ddbbb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f25d2242e77844049689ac0847990d2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f2f864d8a5d3414ea9f70bbd3fce230e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_20825c622aaa4f58a85e2d335ae18173",
       "max": 1000,
       "style": "IPY_MODEL_c8e1e0a4ff004dffba7e844fb865f32b",
       "value": 1000
      }
     },
     "f8015f3a444249edbf21bf3378c10b16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f904a27a7136468d9405e18a9e188fcc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_98e41e7670354a05abb23c8596b76a43",
       "max": 4851,
       "style": "IPY_MODEL_3ce7df172c0241768e0cf8afe14ac3d2",
       "value": 4851
      }
     },
     "f99299987f204b10a13c4678ac4dc00f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8771aa97674b437d87d0ec72c3c2129c",
        "IPY_MODEL_74e4ed68b9fc4ee0b89dcdfa1cf23769",
        "IPY_MODEL_96ee09d822b94431945bc8d4136f63a0"
       ],
       "layout": "IPY_MODEL_c0bf33ebab5144a5b8d28513f0d18423"
      }
     },
     "fc863b5ddbc44871bfe4003334b2f78f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ffa12f0ac90141d9b93bfa07b695b2d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5c4b783063fb40c4a7d0a95f2bfc388b",
        "IPY_MODEL_f904a27a7136468d9405e18a9e188fcc",
        "IPY_MODEL_18722a725e3a41a49d776fe219e5add8"
       ],
       "layout": "IPY_MODEL_7afc7f3491234b71a6f3199e65dd6cef"
      }
     },
     "ffcf4e969e974032ad84095d3f742ade": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8391fd72391e45fca3beb75d5bc62f49",
        "IPY_MODEL_f2f864d8a5d3414ea9f70bbd3fce230e",
        "IPY_MODEL_831d9afd71b84ccbae408482ffd6d436"
       ],
       "layout": "IPY_MODEL_d759b465aee647a2bf894e1fab1d4005"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
