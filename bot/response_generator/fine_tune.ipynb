{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:33.723658Z",
     "iopub.status.busy": "2024-03-16T23:57:33.723267Z",
     "iopub.status.idle": "2024-03-16T23:57:35.229179Z",
     "shell.execute_reply": "2024-03-16T23:57:35.228635Z"
    },
    "id": "n5kH6OUjdubg",
    "outputId": "64186f8c-7b95-401c-85c1-1bd71e2c0067",
    "ExecuteTime": {
     "end_time": "2024-04-15T19:03:28.470585Z",
     "start_time": "2024-04-15T19:03:25.803223Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import huggingface_hub\n",
    "import torch\n",
    "from accelerate import DataLoaderConfiguration\n",
    "\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "282497571fdf445fa591bb72ae0551b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'top_k_top_p_filtering' from 'transformers' (/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpeft\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LoraConfig\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtrl\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SFTTrainer, DataCollatorForCompletionOnlyLM\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/trl/__init__.py:5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# flake8: noqa\u001B[39;00m\n\u001B[1;32m      3\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.7.11\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m set_seed\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01menvironment\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TextEnvironment, TextHistory\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mextras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BestOfNSampler\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/trl/core.py:25\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pad_sequence\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m top_k_top_p_filtering\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimport_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_npu_available, is_xpu_available\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'top_k_top_p_filtering' from 'transformers' (/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_model: str = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer: str = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "name_or_path_for_fine_tuned_model: str = \"\"\n",
    "experiment_detail: str = \"\"\n",
    "wandb_mode: str = \"disabled\"\n",
    "num_epochs: int = 1\n",
    "enable_flash_attention_2: bool = False\n",
    "system_prompt_mode: str = \"disabled\"\n",
    "if system_prompt_mode == \"disabled\":\n",
    "    system_prompt = None\n",
    "else:\n",
    "    system_prompt = \"\" if system_prompt_mode == \"default\" else \"some what\"\n",
    "chat_template_file: str = \"./chat_template/gemma.txt\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chat_template: dict = eval(open(chat_template_file, \"r\", encoding=\"utf-8\", closefd=True).read())",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:35.230819Z",
     "iopub.status.busy": "2024-03-16T23:57:35.230661Z",
     "iopub.status.idle": "2024-03-16T23:57:35.234878Z",
     "shell.execute_reply": "2024-03-16T23:57:35.234632Z"
    }
   },
   "source": [
    "# prevent env load failed\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:35.236038Z",
     "iopub.status.busy": "2024-03-16T23:57:35.235956Z",
     "iopub.status.idle": "2024-03-16T23:57:35.484723Z",
     "shell.execute_reply": "2024-03-16T23:57:35.483075Z"
    }
   },
   "source": [
    "huggingface_hub.login(token=os.environ.get(\"HF_TOKEN\", \"\"), add_to_git_credential=True)\n",
    "wandb.login(key=os.environ.get(\"WANDB_API_KEY\", \"\"), relogin=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wandb_config: dict = {\n",
    "    \"base_model\": base_model,\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"name_or_path_for_fine_tuned_model\": name_or_path_for_fine_tuned_model,\n",
    "    \"system_prompt\": system_prompt,\n",
    "    \"chat_template\": chat_template[\"template\"],\n",
    "    \"instruction_template\": chat_template[\"instruction\"],\n",
    "    \"response_template\": chat_template[\"response\"],\n",
    "    \"special_tokens\": chat_template[\"special_tokens\"]\n",
    "}\n",
    "wandb.init(\n",
    "    job_type=\"fine-tuning\",\n",
    "    config=wandb_config,\n",
    "    project=\"emotion-chat-bot-ncu\",\n",
    "    group=\"Response Generator\",\n",
    "    notes=experiment_detail,\n",
    "    mode=wandb_mode,\n",
    "    resume=\"auto\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:35.502423Z",
     "iopub.status.busy": "2024-03-16T23:57:35.502277Z",
     "iopub.status.idle": "2024-03-16T23:57:39.768709Z",
     "shell.execute_reply": "2024-03-16T23:57:39.768215Z"
    }
   },
   "source": [
    "dataset = load_dataset(\"daily_dialog\",\n",
    "                       split=\"train\",\n",
    "                       num_proc=16,\n",
    "                       trust_remote_code=True).remove_columns(\"act\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:39.775160Z",
     "iopub.status.busy": "2024-03-16T23:57:39.775072Z",
     "iopub.status.idle": "2024-03-16T23:57:39.777064Z",
     "shell.execute_reply": "2024-03-16T23:57:39.776892Z"
    }
   },
   "source": [
    "dataset = dataset.rename_column(\"emotion\", \"emotion_id\")\n",
    "emotion_labels: list = dataset.features[\"emotion_id\"].feature.names\n",
    "emotion_labels[0] = \"neutral\"\n",
    "dataset = dataset.map(lambda samples: {\n",
    "    \"emotion\": [[emotion_labels[emotion_id] for emotion_id in sample] for sample in samples]\n",
    "}, input_columns=\"emotion_id\", remove_columns=\"emotion_id\", batched=True, num_proc=16)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:39.798132Z",
     "iopub.status.busy": "2024-03-16T23:57:39.798058Z",
     "iopub.status.idle": "2024-03-16T23:57:39.808037Z",
     "shell.execute_reply": "2024-03-16T23:57:39.807875Z"
    }
   },
   "source": [
    "dataset = dataset.map(lambda samples: {\n",
    "    \"dialog\": [[dialog.strip() for dialog in sample] for sample in samples]\n",
    "}, input_columns=\"dialog\", batched=True, num_proc=16)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = dataset.map(lambda samples: {\n",
    "    \"prompt\": [[{\n",
    "        \"role\": \"user\" if i % 2 == 0 else \"assistant\",\n",
    "        \"content\": {\"emotion\": emotion, \"dialog\": dialog}\n",
    "    }\n",
    "        for i, (emotion, dialog) in enumerate(zip(sample[0], sample[1]))]\n",
    "        for sample in zip(samples[\"emotion\"], samples[\"dialog\"])]\n",
    "}, remove_columns=[\"emotion\", \"dialog\"], batched=True, num_proc=16)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = dataset.map(lambda samples: {\n",
    "    \"prompt\": [sample[:-1] if len(sample) % 2 == 1 else sample for sample in samples]\n",
    "}, input_columns=\"prompt\", batched=True, num_proc=16)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if system_prompt_mode != \"disabled\":\n",
    "    dataset = dataset.map(lambda samples: {\n",
    "        \"prompt\": [[{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": {\"emotion\": None, \"dialog\": system_prompt}\n",
    "        }] + sample for sample in samples]\n",
    "    }, input_columns=\"prompt\", batched=True, num_proc=16)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:39.880713Z",
     "iopub.status.busy": "2024-03-16T23:57:39.880651Z",
     "iopub.status.idle": "2024-03-16T23:57:40.123038Z",
     "shell.execute_reply": "2024-03-16T23:57:40.122721Z"
    }
   },
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.clean_up_tokenization_spaces = True\n",
    "tokenizer.chat_template = chat_template[\"template\"]\n",
    "tokenizer.add_special_tokens(chat_template[\"special_tokens\"], replace_additional_special_tokens=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prompt_compose(sample: str):\n",
    "    return tokenizer.apply_chat_template(sample,\n",
    "                                         tokenize=False,\n",
    "                                         padding=True,\n",
    "                                         max_length=4096,\n",
    "                                         return_tensors=\"pt\"\n",
    "                                         )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = dataset.map(lambda sample: {\n",
    "    \"prompt\": prompt_compose(sample)\n",
    "}, input_columns=\"prompt\", num_proc=16)\n",
    "wandb.config[\"example_prompt\"] = dataset[0][\"prompt\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# dataset = dataset.train_test_split(test_size=0.1)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:40.124510Z",
     "iopub.status.busy": "2024-03-16T23:57:40.124435Z",
     "iopub.status.idle": "2024-03-16T23:57:40.126589Z",
     "shell.execute_reply": "2024-03-16T23:57:40.126420Z"
    }
   },
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "quantization_config = quantization_config if torch.cuda.is_available() else None\n",
    "wandb.config[\"quantization_configuration\"] = quantization_config.to_dict() if quantization_config is not None else {}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:40.127624Z",
     "iopub.status.busy": "2024-03-16T23:57:40.127535Z",
     "iopub.status.idle": "2024-03-16T23:57:40.128904Z",
     "shell.execute_reply": "2024-03-16T23:57:40.128749Z"
    }
   },
   "source": [
    "lora_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "wandb.config[\"lora_configuration\"] = lora_config.to_dict()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataloader_config = DataLoaderConfiguration(\n",
    "#     dispatch_batches=None,\n",
    "#     split_batches=False,\n",
    "#     even_batches=True,\n",
    "#     use_seedable_sampler=True\n",
    "# )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:40.131918Z",
     "iopub.status.busy": "2024-03-16T23:57:40.131814Z",
     "iopub.status.idle": "2024-03-16T23:57:40.144189Z",
     "shell.execute_reply": "2024-03-16T23:57:40.143996Z"
    }
   },
   "source": [
    "trainer_arguments = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    overwrite_output_dir=True,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=4,\n",
    "    # per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    # eval_accumulation_steps=1,\n",
    "    # eval_delay=0.5,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=num_epochs,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    warmup_ratio=0.03,\n",
    "    max_steps=-1,\n",
    "    logging_steps=25,\n",
    "    save_steps=25,\n",
    "    save_total_limit=5,\n",
    "    bf16=False,\n",
    "    fp16=False,\n",
    "    dataloader_num_workers=16,\n",
    "    # load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"loss\",\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    group_by_length=True,\n",
    "    report_to=[\"wandb\"],\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": True},\n",
    "    auto_find_batch_size=True,\n",
    "    torch_compile=False,\n",
    "    resume_from_checkpoint=True\n",
    ")\n",
    "wandb.config[\"trainer_arguments\"] = trainer_arguments.to_dict()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "flash_attention: str = \"flash_attention_2\" if enable_flash_attention_2 else None",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:40.145206Z",
     "iopub.status.busy": "2024-03-16T23:57:40.145104Z",
     "iopub.status.idle": "2024-03-16T23:57:43.983811Z",
     "shell.execute_reply": "2024-03-16T23:57:43.983512Z"
    }
   },
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quantization_config,\n",
    "    attn_implementation=flash_attention,\n",
    "    pretraining_tp=1,\n",
    "    use_cache=False,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "wandb.config[\"base_model_configuration\"] = base_model.config.to_dict()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setup Tuner"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    chat_template[\"response\"],\n",
    "    instruction_template=chat_template[\"instruction\"],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508,
     "referenced_widgets": [
      "636a931c33cd415ba1eb6c4721080fd2",
      "dda7944038c34f70803c926436ffcfaf",
      "d25d9974d04344509944bbea7b8e3268",
      "8a836fa75d6b400fb3187ec1bf87946a",
      "f5404ba31d8a4295b9da0c26db9b2439",
      "1f14aff2634a48b493cd94733c356a2a",
      "edcdc867e2f44851a25fca997a0944de",
      "1ed8684669ed48629790b5b902c577ba",
      "c55e6bd1be2643d1b846f2d7b8cbf234",
      "d03a30aa2db84d29a8c4a3e34466644d",
      "12c4eef0a8c640349e257d0973a58a41"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:43.987566Z",
     "iopub.status.busy": "2024-03-16T23:57:43.987450Z",
     "iopub.status.idle": "2024-03-16T23:57:44.057094Z",
     "shell.execute_reply": "2024-03-16T23:57:44.056880Z"
    },
    "id": "TSsPNqspeFt5",
    "outputId": "58856f44-014b-478e-edd1-fef917d76766"
   },
   "source": [
    "tuner = SFTTrainer(\n",
    "    model=base_model,\n",
    "    args=trainer_arguments,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    # eval_dataset=dataset[\"test\"],\n",
    "    peft_config=lora_config,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=4096,\n",
    "    dataset_num_proc=16\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:44.058478Z",
     "iopub.status.busy": "2024-03-16T23:57:44.058352Z",
     "iopub.status.idle": "2024-03-17T17:29:31.299778Z",
     "shell.execute_reply": "2024-03-17T17:29:31.299586Z"
    }
   },
   "source": [
    "tuner.train()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tuner.model = torch.compile(tuner.model)\n",
    "tuner.save_model(\"./model\")\n",
    "wandb.save(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-17T17:29:31.307746Z",
     "iopub.status.busy": "2024-03-17T17:29:31.307452Z",
     "iopub.status.idle": "2024-03-17T17:29:31.742306Z",
     "shell.execute_reply": "2024-03-17T17:29:31.741999Z"
    }
   },
   "source": "wandb.finish()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2b7f52a715924339b2d2ca3d5a0fc02d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2bd2c1dc7b7447eca8c01a9ed88a6001": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9545dbca917d4c529de8cab5e88ab802",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c0bf096919ce437e82366fab1aed6d66",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "6190f0ee16244d5f80c2145654259e51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9545dbca917d4c529de8cab5e88ab802": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9955ff5df3b94d6f9d2b6e27df304686": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e6c4ff3fa1d5475fb22b605b702c5155",
       "placeholder": "​",
       "style": "IPY_MODEL_b74da2f5e9694f8ab607998a522d91ce",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "b48789d2c20a4140b447ae28f84913d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2b7f52a715924339b2d2ca3d5a0fc02d",
       "placeholder": "​",
       "style": "IPY_MODEL_6190f0ee16244d5f80c2145654259e51",
       "tabbable": null,
       "tooltip": null,
       "value": " 2/2 [00:03&lt;00:00,  1.42s/it]"
      }
     },
     "b74da2f5e9694f8ab607998a522d91ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c0bf096919ce437e82366fab1aed6d66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c1399fbbd87a43caa83b8d25b83f4ccc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6c4ff3fa1d5475fb22b605b702c5155": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4010bea48cf46569f8f2578a7830461": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9955ff5df3b94d6f9d2b6e27df304686",
        "IPY_MODEL_2bd2c1dc7b7447eca8c01a9ed88a6001",
        "IPY_MODEL_b48789d2c20a4140b447ae28f84913d0"
       ],
       "layout": "IPY_MODEL_c1399fbbd87a43caa83b8d25b83f4ccc",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
