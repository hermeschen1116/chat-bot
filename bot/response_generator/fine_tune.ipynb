{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:33.723658Z",
     "iopub.status.busy": "2024-03-16T23:57:33.723267Z",
     "iopub.status.idle": "2024-03-16T23:57:35.229179Z",
     "shell.execute_reply": "2024-03-16T23:57:35.228635Z"
    },
    "id": "n5kH6OUjdubg",
    "outputId": "64186f8c-7b95-401c-85c1-1bd71e2c0067",
    "ExecuteTime": {
     "end_time": "2024-04-14T14:21:44.054900Z",
     "start_time": "2024-04-14T14:21:42.533671Z"
    }
   },
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import huggingface_hub\n",
    "import torch\n",
    "from accelerate import DataLoaderConfiguration\n",
    "\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T14:21:45.786048Z",
     "start_time": "2024-04-14T14:21:45.783673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model: str = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer: str = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "name_or_path_for_fine_tuned_model: str = \"\"\n",
    "experiment_detail: str = \"\"\n",
    "wandb_mode: str = \"disabled\"\n",
    "num_epochs: int = 1\n",
    "enable_flash_attention_2: bool = False\n",
    "system_prompt_mode: str = \"disabled\"\n",
    "if system_prompt_mode == \"disabled\":\n",
    "    system_prompt = None\n",
    "else:\n",
    "    system_prompt = \"\" if system_prompt_mode == \"default\" else \"some what\"\n",
    "chat_template_file: str = \"./chat_template/gemma.txt\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T14:21:58.376566Z",
     "start_time": "2024-04-14T14:21:58.373475Z"
    }
   },
   "cell_type": "code",
   "source": "chat_template: dict = eval(open(chat_template_file, \"r\", encoding=\"utf-8\", closefd=True).read())",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:35.230819Z",
     "iopub.status.busy": "2024-03-16T23:57:35.230661Z",
     "iopub.status.idle": "2024-03-16T23:57:35.234878Z",
     "shell.execute_reply": "2024-03-16T23:57:35.234632Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:21:58.619529Z",
     "start_time": "2024-04-14T14:21:58.613610Z"
    }
   },
   "source": [
    "# prevent env load failed\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:35.236038Z",
     "iopub.status.busy": "2024-03-16T23:57:35.235956Z",
     "iopub.status.idle": "2024-03-16T23:57:35.484723Z",
     "shell.execute_reply": "2024-03-16T23:57:35.483075Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:00.134931Z",
     "start_time": "2024-04-14T14:21:58.870767Z"
    }
   },
   "source": [
    "huggingface_hub.login(token=os.environ.get(\"HF_TOKEN\", \"\"), add_to_git_credential=True)\n",
    "wandb.login(key=os.environ.get(\"WANDB_API_KEY\", \"\"), relogin=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/hermeschen/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/hermeschen/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:01.983890Z",
     "start_time": "2024-04-14T14:22:01.976532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wandb_config: dict = {\n",
    "    \"base_model\": base_model,\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"name_or_path_for_fine_tuned_model\": name_or_path_for_fine_tuned_model,\n",
    "    \"system_prompt\": system_prompt,\n",
    "    \"chat_template\": chat_template[\"template\"],\n",
    "    \"instruction_template\": chat_template[\"instruction\"],\n",
    "    \"response_template\": chat_template[\"response\"],\n",
    "    \"special_tokens\": chat_template[\"special_tokens\"]\n",
    "}\n",
    "wandb.init(\n",
    "    job_type=\"fine-tuning\",\n",
    "    config=wandb_config,\n",
    "    project=\"emotion-chat-bot-ncu\",\n",
    "    group=\"Response Generator\",\n",
    "    notes=experiment_detail,\n",
    "    mode=wandb_mode,\n",
    "    resume=\"auto\"\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:35.502423Z",
     "iopub.status.busy": "2024-03-16T23:57:35.502277Z",
     "iopub.status.idle": "2024-03-16T23:57:39.768709Z",
     "shell.execute_reply": "2024-03-16T23:57:39.768215Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:30.537304Z",
     "start_time": "2024-04-14T14:22:21.936169Z"
    }
   },
   "source": [
    "dataset = load_dataset(\"daily_dialog\",\n",
    "                       split=\"train[:10]+validation[:10]\",\n",
    "                       num_proc=16,\n",
    "                       trust_remote_code=True).remove_columns(\"act\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:39.775160Z",
     "iopub.status.busy": "2024-03-16T23:57:39.775072Z",
     "iopub.status.idle": "2024-03-16T23:57:39.777064Z",
     "shell.execute_reply": "2024-03-16T23:57:39.776892Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:30.903097Z",
     "start_time": "2024-04-14T14:22:30.538005Z"
    }
   },
   "source": [
    "dataset = dataset.rename_column(\"emotion\", \"emotion_id\")\n",
    "emotion_labels: list = dataset.features[\"emotion_id\"].feature.names\n",
    "emotion_labels[0] = \"neutral\"\n",
    "dataset = dataset.map(lambda samples: {\n",
    "    \"emotion\": [[emotion_labels[emotion_id] for emotion_id in sample] for sample in samples]\n",
    "}, input_columns=\"emotion_id\", remove_columns=\"emotion_id\", batched=True, num_proc=16)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/20 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "138dcafc5997466096e896a899e1164c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:39.798132Z",
     "iopub.status.busy": "2024-03-16T23:57:39.798058Z",
     "iopub.status.idle": "2024-03-16T23:57:39.808037Z",
     "shell.execute_reply": "2024-03-16T23:57:39.807875Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:31.291322Z",
     "start_time": "2024-04-14T14:22:30.910149Z"
    }
   },
   "source": [
    "dataset = dataset.map(lambda samples: {\n",
    "    \"dialog\": [[dialog.strip() for dialog in sample] for sample in samples]\n",
    "}, input_columns=\"dialog\", batched=True, num_proc=16)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/20 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68765f3095a940ba932cb9fd2af32f59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:31.616724Z",
     "start_time": "2024-04-14T14:22:31.292954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = dataset.map(lambda samples: {\n",
    "    \"prompt\": [[{\n",
    "        \"role\": \"user\" if i % 2 == 0 else \"assistant\",\n",
    "        \"content\": {\"emotion\": emotion, \"dialog\": dialog}\n",
    "    }\n",
    "        for i, (emotion, dialog) in enumerate(zip(sample[0], sample[1]))]\n",
    "        for sample in zip(samples[\"emotion\"], samples[\"dialog\"])]\n",
    "}, remove_columns=[\"emotion\", \"dialog\"], batched=True, num_proc=16)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/20 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5cf29861ae0e4126ac9c4735afb4e80c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:32.408019Z",
     "start_time": "2024-04-14T14:22:31.617985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = dataset.map(lambda samples: {\n",
    "    \"prompt\": [sample[:-1] if len(sample) % 2 == 1 else sample for sample in samples]\n",
    "}, input_columns=\"prompt\", batched=True, num_proc=16)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/20 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fffa75e6fd7c4d22addf688ae773bfcf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:32.411761Z",
     "start_time": "2024-04-14T14:22:32.409146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if system_prompt_mode != \"disabled\":\n",
    "    dataset = dataset.map(lambda samples: {\n",
    "        \"prompt\": [[{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": {\"emotion\": None, \"dialog\": system_prompt}\n",
    "        }] + sample for sample in samples]\n",
    "    }, input_columns=\"prompt\", batched=True, num_proc=16)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:39.880713Z",
     "iopub.status.busy": "2024-03-16T23:57:39.880651Z",
     "iopub.status.idle": "2024-03-16T23:57:40.123038Z",
     "shell.execute_reply": "2024-03-16T23:57:40.122721Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:32.663711Z",
     "start_time": "2024-04-14T14:22:32.412510Z"
    }
   },
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.clean_up_tokenization_spaces = True\n",
    "tokenizer.chat_template = chat_template[\"template\"]\n",
    "tokenizer.add_special_tokens(chat_template[\"special_tokens\"], replace_additional_special_tokens=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:32.665792Z",
     "start_time": "2024-04-14T14:22:32.664252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prompt_compose(sample: str):\n",
    "    return tokenizer.apply_chat_template(sample,\n",
    "                                         tokenize=False,\n",
    "                                         padding=True,\n",
    "                                         max_length=4096,\n",
    "                                         return_tensors=\"pt\"\n",
    "                                         )"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:32.938652Z",
     "start_time": "2024-04-14T14:22:32.666354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = dataset.map(lambda sample: {\n",
    "    \"prompt\": prompt_compose(sample)\n",
    "}, input_columns=\"prompt\", num_proc=16)\n",
    "wandb.config[\"example_prompt\"] = dataset[0][\"prompt\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/20 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae4cb1aa347d4bf1b13189ae89bee256"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:32.948424Z",
     "start_time": "2024-04-14T14:22:32.939825Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = dataset.train_test_split(test_size=0.1)",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:40.124510Z",
     "iopub.status.busy": "2024-03-16T23:57:40.124435Z",
     "iopub.status.idle": "2024-03-16T23:57:40.126589Z",
     "shell.execute_reply": "2024-03-16T23:57:40.126420Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:32.963717Z",
     "start_time": "2024-04-14T14:22:32.950196Z"
    }
   },
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "quantization_config = quantization_config if torch.cuda.is_available() else None\n",
    "wandb.config[\"quantization_configuration\"] = quantization_config.to_dict() if quantization_config is not None else {}"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:40.127624Z",
     "iopub.status.busy": "2024-03-16T23:57:40.127535Z",
     "iopub.status.idle": "2024-03-16T23:57:40.128904Z",
     "shell.execute_reply": "2024-03-16T23:57:40.128749Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:35.466775Z",
     "start_time": "2024-04-14T14:22:35.464107Z"
    }
   },
   "source": [
    "lora_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "wandb.config[\"lora_configuration\"] = lora_config.to_dict()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# dataloader_config = DataLoaderConfiguration(\n",
    "#     dispatch_batches=None,\n",
    "#     split_batches=False,\n",
    "#     even_batches=True,\n",
    "#     use_seedable_sampler=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:40.131918Z",
     "iopub.status.busy": "2024-03-16T23:57:40.131814Z",
     "iopub.status.idle": "2024-03-16T23:57:40.144189Z",
     "shell.execute_reply": "2024-03-16T23:57:40.143996Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:36.047288Z",
     "start_time": "2024-04-14T14:22:35.989132Z"
    }
   },
   "source": [
    "trainer_arguments = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    eval_accumulation_steps=1,\n",
    "    eval_delay=500,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=num_epochs,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    warmup_ratio=0.03,\n",
    "    max_steps=-1,\n",
    "    logging_steps=25,\n",
    "    save_steps=25,\n",
    "    save_total_limit=5,\n",
    "    bf16=False,\n",
    "    fp16=False,\n",
    "    dataloader_num_workers=16,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    group_by_length=True,\n",
    "    report_to=[\"wandb\"],\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": True},\n",
    "    auto_find_batch_size=True,\n",
    "    torch_compile=False,\n",
    "    resume_from_checkpoint=True\n",
    ")\n",
    "wandb.config[\"trainer_arguments\"] = trainer_arguments.to_dict()"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T14:22:37.622165Z",
     "start_time": "2024-04-14T14:22:37.618092Z"
    }
   },
   "cell_type": "code",
   "source": "flash_attention: str = \"flash_attention_2\" if enable_flash_attention_2 else None",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:40.145206Z",
     "iopub.status.busy": "2024-03-16T23:57:40.145104Z",
     "iopub.status.idle": "2024-03-16T23:57:43.983811Z",
     "shell.execute_reply": "2024-03-16T23:57:43.983512Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:28:40.549172Z",
     "start_time": "2024-04-14T14:22:38.221443Z"
    }
   },
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quantization_config,\n",
    "    attn_implementation=flash_attention,\n",
    "    pretraining_tp=1,\n",
    "    use_cache=False,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "wandb.config[\"base_model_configuration\"] = base_model.config.to_dict()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abfd198512b3439cb7e5876b1f8b9d0a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c0ab2c544934a58bb9cda4cc4e43d95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ce74bb7842f480f864e123cda8755b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06a08ef5a8ba4f0991ec1e31c7028639"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdfdee2fc5fa40ddabfdbc3675c32015"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e34d9cf3b5ba4f8582bf48971954502d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11bb729af31d414f99047c87b250e57b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setup Tuner"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T14:30:39.825124Z",
     "start_time": "2024-04-14T14:30:39.822691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    chat_template[\"response\"],\n",
    "    instruction_template=chat_template[\"instruction\"],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508,
     "referenced_widgets": [
      "636a931c33cd415ba1eb6c4721080fd2",
      "dda7944038c34f70803c926436ffcfaf",
      "d25d9974d04344509944bbea7b8e3268",
      "8a836fa75d6b400fb3187ec1bf87946a",
      "f5404ba31d8a4295b9da0c26db9b2439",
      "1f14aff2634a48b493cd94733c356a2a",
      "edcdc867e2f44851a25fca997a0944de",
      "1ed8684669ed48629790b5b902c577ba",
      "c55e6bd1be2643d1b846f2d7b8cbf234",
      "d03a30aa2db84d29a8c4a3e34466644d",
      "12c4eef0a8c640349e257d0973a58a41"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:43.987566Z",
     "iopub.status.busy": "2024-03-16T23:57:43.987450Z",
     "iopub.status.idle": "2024-03-16T23:57:44.057094Z",
     "shell.execute_reply": "2024-03-16T23:57:44.056880Z"
    },
    "id": "TSsPNqspeFt5",
    "outputId": "58856f44-014b-478e-edd1-fef917d76766",
    "ExecuteTime": {
     "end_time": "2024-04-14T14:30:41.994580Z",
     "start_time": "2024-04-14T14:30:40.732855Z"
    }
   },
   "source": [
    "tuner = SFTTrainer(\n",
    "    model=base_model,\n",
    "    args=trainer_arguments,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    peft_config=lora_config,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=4096,\n",
    "    dataset_num_proc=16\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/16 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5509295e610443319b4d8c96acca9e46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 4. Reducing num_proc to 4 for dataset of size 4.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d75a7f34292145f8ab5835d2ed288296"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-16T23:57:44.058478Z",
     "iopub.status.busy": "2024-03-16T23:57:44.058352Z",
     "iopub.status.idle": "2024-03-17T17:29:31.299778Z",
     "shell.execute_reply": "2024-03-17T17:29:31.299586Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:31:18.726824Z",
     "start_time": "2024-04-14T14:30:43.066527Z"
    }
   },
   "source": [
    "tuner.train()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-14 23:30:45,350] [16/0] torch._dynamo.variables.higher_order_ops: [WARNING] speculate_subgraph: while introspecting torch.utils.checkpoint.checkpoint, we were unable to trace function `_wrapped_call_impl` into a single graph. This means that Dynamo was unable to prove safety for this API and will fall back to eager-mode PyTorch, which could lead to a slowdown.\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR] hasattr TupleVariable to\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR] Traceback (most recent call last):\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py\", line 242, in speculate_subgraph\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     output = f.call_function(tx, args, sub_kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 294, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return super().call_function(tx, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 248, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return super().call_function(tx, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 81, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return tx.inline_user_function_return(\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     tracer.run()\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     and self.step()\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]         ^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     getattr(self, inst.opname)(inst)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return inner_fn(self, inst)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1252, in CALL_FUNCTION_EX\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     self.call_function(fn, argsvars.items, kwargsvars.items)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 294, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return super().call_function(tx, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 248, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return super().call_function(tx, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 81, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return tx.inline_user_function_return(\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     tracer.run()\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     and self.step()\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]         ^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     getattr(self, inst.opname)(inst)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return inner_fn(self, inst)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1252, in CALL_FUNCTION_EX\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     self.call_function(fn, argsvars.items, kwargsvars.items)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 617, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return self.func.call_function(tx, merged_args, merged_kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 248, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return super().call_function(tx, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 81, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return tx.inline_user_function_return(\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     tracer.run()\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     and self.step()\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]         ^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     getattr(self, inst.opname)(inst)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return inner_fn(self, inst)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1252, in CALL_FUNCTION_EX\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     self.call_function(fn, argsvars.items, kwargsvars.items)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 294, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return super().call_function(tx, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 248, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return super().call_function(tx, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 81, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return tx.inline_user_function_return(\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     tracer.run()\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     and self.step()\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]         ^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     getattr(self, inst.opname)(inst)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return inner_fn(self, inst)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1802, in CALL\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     self.call_function(fn, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 248, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return super().call_function(tx, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 81, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return tx.inline_user_function_return(\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     tracer.run()\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     and self.step()\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]         ^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     getattr(self, inst.opname)(inst)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return inner_fn(self, inst)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1802, in CALL\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     self.call_function(fn, args, kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 651, in call_function\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     result = handler(tx, *args, **kwargs)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 1069, in call_hasattr\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     return obj.call_hasattr(tx, name)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/variables/base.py\", line 306, in call_hasattr\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     unimplemented(f\"hasattr {self.__class__.__name__} {name}\")\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]   File \"/home/hermeschen/.cache/pypoetry/virtualenvs/chat-bot-uhayQKRl-py3.11/lib/python3.11/site-packages/torch/_dynamo/exc.py\", line 193, in unimplemented\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR]     raise Unsupported(msg)\n",
      "[2024-04-14 23:30:45,351] [16/0] torch._dynamo.variables.higher_order_ops: [ERROR] torch._dynamo.exc.Unsupported: hasattr TupleVariable to\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4, training_loss=0.0, metrics={'train_runtime': 31.7906, 'train_samples_per_second': 0.503, 'train_steps_per_second': 0.126, 'total_flos': 200885839331328.0, 'train_loss': 0.0, 'epoch': 1.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-17T17:29:31.307746Z",
     "iopub.status.busy": "2024-03-17T17:29:31.307452Z",
     "iopub.status.idle": "2024-03-17T17:29:31.742306Z",
     "shell.execute_reply": "2024-03-17T17:29:31.741999Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-14T14:31:18.729690Z",
     "start_time": "2024-04-14T14:31:18.727488Z"
    }
   },
   "source": "wandb.finish()",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2b7f52a715924339b2d2ca3d5a0fc02d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2bd2c1dc7b7447eca8c01a9ed88a6001": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9545dbca917d4c529de8cab5e88ab802",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c0bf096919ce437e82366fab1aed6d66",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "6190f0ee16244d5f80c2145654259e51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9545dbca917d4c529de8cab5e88ab802": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9955ff5df3b94d6f9d2b6e27df304686": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e6c4ff3fa1d5475fb22b605b702c5155",
       "placeholder": "​",
       "style": "IPY_MODEL_b74da2f5e9694f8ab607998a522d91ce",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "b48789d2c20a4140b447ae28f84913d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2b7f52a715924339b2d2ca3d5a0fc02d",
       "placeholder": "​",
       "style": "IPY_MODEL_6190f0ee16244d5f80c2145654259e51",
       "tabbable": null,
       "tooltip": null,
       "value": " 2/2 [00:03&lt;00:00,  1.42s/it]"
      }
     },
     "b74da2f5e9694f8ab607998a522d91ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c0bf096919ce437e82366fab1aed6d66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c1399fbbd87a43caa83b8d25b83f4ccc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6c4ff3fa1d5475fb22b605b702c5155": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4010bea48cf46569f8f2578a7830461": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9955ff5df3b94d6f9d2b6e27df304686",
        "IPY_MODEL_2bd2c1dc7b7447eca8c01a9ed88a6001",
        "IPY_MODEL_b48789d2c20a4140b447ae28f84913d0"
       ],
       "layout": "IPY_MODEL_c1399fbbd87a43caa83b8d25b83f4ccc",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
